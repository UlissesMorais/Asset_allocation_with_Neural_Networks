{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101d2b6f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d53e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "866f6073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5b9a34",
   "metadata": {},
   "source": [
    "## Train/val/pred split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa1801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_datasets():\n",
    "            \n",
    "    # import training and prediction datasets\n",
    "    train_dataset = pd.read_csv(r'./trainpred_dataset/FIA1_20142022_train_dataset.csv')\n",
    "    pred_dataset = pd.read_csv(r'./trainpred_dataset/FIA1_20142022_pred_dataset.csv')\n",
    "    train_dataset[\"period\"] = train_dataset[\"period\"].astype(int)\n",
    "    \n",
    "    windows = train_dataset[\"window\"].unique()\n",
    "    \n",
    "    # list with portfolios\n",
    "    pred_port_list = pred_dataset[pred_dataset[\"window\"] == 0].iloc[:,:4].values.tolist()\n",
    "    \n",
    "    train_win_list = []\n",
    "    pred_win_list = []\n",
    "    \n",
    "    # split datasets by windows\n",
    "    for w in windows:\n",
    "        \n",
    "        train = train_dataset[train_dataset[\"window\"] == w]\n",
    "        pred = pred_dataset[pred_dataset[\"window\"] == w]\n",
    "        \n",
    "        # drop funds columns\n",
    "        train_prev = train.drop(train.columns[:4], axis=1).reset_index(drop=True)\n",
    "        pred_prev = pred.drop(pred.columns[:4], axis=1).reset_index(drop=True)\n",
    "        \n",
    "        train_win_list.append(train_prev)\n",
    "        pred_win_list.append(pred_prev)\n",
    "        \n",
    "    \n",
    "    return train_win_list, pred_win_list, pred_port_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "487d05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_pred_split():\n",
    "    \n",
    "    train_sets, pred_sets, pred_port_list = import_datasets()\n",
    "    \n",
    "    # splits the training dataset in training and validation sets\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=42)\n",
    "    \n",
    "    dic_train = {}\n",
    "    dic_val = {}\n",
    "    dic_pred = {}\n",
    "    \n",
    "    # stratified split per periods\n",
    "    for w, train_set in enumerate(train_sets):\n",
    "        for train_index, val_index in split.split(train_set, train_set[\"period\"]):\n",
    "            strat_train_set = train_set.loc[train_index]\n",
    "            strat_val_set = train_set.loc[val_index]\n",
    "            \n",
    "            X_train = strat_train_set.drop(strat_train_set.columns[-6:], axis=1)\n",
    "            y_train = strat_train_set.loc[:, [\"w_F1\", \"w_F2\",\"w_F3\",\"w_F4\"]]\n",
    "            \n",
    "            X_val = strat_val_set.drop(strat_val_set.columns[-6:], axis=1)\n",
    "            y_val = strat_val_set.loc[:, [\"w_F1\", \"w_F2\",\"w_F3\",\"w_F4\"]]\n",
    "            \n",
    "            X_pred = pred_sets[w].drop(pred_sets[w].columns[-6:], axis=1)\n",
    "            \n",
    "            dic_train[w] = [X_train, y_train]\n",
    "            dic_val[w] = [X_val, y_val]\n",
    "            dic_pred[w] = X_pred\n",
    "\n",
    "\n",
    "    return dic_train, dic_val, dic_pred, pred_port_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25619bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all datasets and portfolios list\n",
    "dic_train, dic_val, dic_pred, pred_port_list = train_val_pred_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "073bd038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ret_F1</th>\n",
       "      <th>ret_F2</th>\n",
       "      <th>ret_F3</th>\n",
       "      <th>ret_F4</th>\n",
       "      <th>rsk_F1</th>\n",
       "      <th>rsk_F2</th>\n",
       "      <th>rsk_F3</th>\n",
       "      <th>rsk_F4</th>\n",
       "      <th>CORR_F1F2</th>\n",
       "      <th>CORR_F1F3</th>\n",
       "      <th>CORR_F1F4</th>\n",
       "      <th>CORR_F2F3</th>\n",
       "      <th>CORR_F2F4</th>\n",
       "      <th>CORR_F3F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66083</th>\n",
       "      <td>0.171939</td>\n",
       "      <td>0.270738</td>\n",
       "      <td>0.394526</td>\n",
       "      <td>0.273058</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.196426</td>\n",
       "      <td>0.141295</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>0.827951</td>\n",
       "      <td>0.729154</td>\n",
       "      <td>0.692460</td>\n",
       "      <td>0.773838</td>\n",
       "      <td>0.716855</td>\n",
       "      <td>0.712572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39709</th>\n",
       "      <td>0.475044</td>\n",
       "      <td>0.489305</td>\n",
       "      <td>0.311326</td>\n",
       "      <td>0.251790</td>\n",
       "      <td>0.384417</td>\n",
       "      <td>0.194289</td>\n",
       "      <td>0.192601</td>\n",
       "      <td>0.198278</td>\n",
       "      <td>0.727292</td>\n",
       "      <td>0.766216</td>\n",
       "      <td>0.756955</td>\n",
       "      <td>0.838467</td>\n",
       "      <td>0.819654</td>\n",
       "      <td>0.928007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88178</th>\n",
       "      <td>0.363362</td>\n",
       "      <td>0.257881</td>\n",
       "      <td>0.375526</td>\n",
       "      <td>0.381995</td>\n",
       "      <td>0.179756</td>\n",
       "      <td>0.181495</td>\n",
       "      <td>0.213341</td>\n",
       "      <td>0.145330</td>\n",
       "      <td>0.894073</td>\n",
       "      <td>0.736210</td>\n",
       "      <td>0.818167</td>\n",
       "      <td>0.736360</td>\n",
       "      <td>0.862172</td>\n",
       "      <td>0.696347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29905</th>\n",
       "      <td>0.200433</td>\n",
       "      <td>0.320284</td>\n",
       "      <td>0.381995</td>\n",
       "      <td>0.310304</td>\n",
       "      <td>0.137747</td>\n",
       "      <td>0.178042</td>\n",
       "      <td>0.182803</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.919326</td>\n",
       "      <td>0.892861</td>\n",
       "      <td>0.796780</td>\n",
       "      <td>0.949429</td>\n",
       "      <td>0.868108</td>\n",
       "      <td>0.906294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68162</th>\n",
       "      <td>0.245617</td>\n",
       "      <td>0.489305</td>\n",
       "      <td>0.212685</td>\n",
       "      <td>0.175012</td>\n",
       "      <td>0.182380</td>\n",
       "      <td>0.194289</td>\n",
       "      <td>0.129613</td>\n",
       "      <td>0.143440</td>\n",
       "      <td>0.847846</td>\n",
       "      <td>0.897266</td>\n",
       "      <td>0.920668</td>\n",
       "      <td>0.805347</td>\n",
       "      <td>0.812089</td>\n",
       "      <td>0.927220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92959</th>\n",
       "      <td>0.294656</td>\n",
       "      <td>0.257881</td>\n",
       "      <td>0.318545</td>\n",
       "      <td>0.314083</td>\n",
       "      <td>0.195730</td>\n",
       "      <td>0.181495</td>\n",
       "      <td>0.144882</td>\n",
       "      <td>0.159112</td>\n",
       "      <td>0.902889</td>\n",
       "      <td>0.898130</td>\n",
       "      <td>0.898642</td>\n",
       "      <td>0.903643</td>\n",
       "      <td>0.877912</td>\n",
       "      <td>0.904116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75337</th>\n",
       "      <td>0.318315</td>\n",
       "      <td>0.244021</td>\n",
       "      <td>0.314083</td>\n",
       "      <td>0.230774</td>\n",
       "      <td>0.312862</td>\n",
       "      <td>0.194807</td>\n",
       "      <td>0.159112</td>\n",
       "      <td>0.205234</td>\n",
       "      <td>0.767546</td>\n",
       "      <td>0.774393</td>\n",
       "      <td>0.779156</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.817841</td>\n",
       "      <td>0.827642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1.080724</td>\n",
       "      <td>0.433474</td>\n",
       "      <td>0.168252</td>\n",
       "      <td>0.611184</td>\n",
       "      <td>0.400353</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.196828</td>\n",
       "      <td>0.132727</td>\n",
       "      <td>0.616322</td>\n",
       "      <td>0.587333</td>\n",
       "      <td>0.560948</td>\n",
       "      <td>0.734766</td>\n",
       "      <td>0.638158</td>\n",
       "      <td>0.615747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85916</th>\n",
       "      <td>0.261629</td>\n",
       "      <td>0.263809</td>\n",
       "      <td>0.240980</td>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.166025</td>\n",
       "      <td>0.147950</td>\n",
       "      <td>0.183468</td>\n",
       "      <td>0.166329</td>\n",
       "      <td>0.939175</td>\n",
       "      <td>0.949920</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0.922402</td>\n",
       "      <td>0.903907</td>\n",
       "      <td>0.955173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68625</th>\n",
       "      <td>0.245617</td>\n",
       "      <td>0.379804</td>\n",
       "      <td>0.239856</td>\n",
       "      <td>0.264161</td>\n",
       "      <td>0.182380</td>\n",
       "      <td>0.193074</td>\n",
       "      <td>0.172665</td>\n",
       "      <td>0.196398</td>\n",
       "      <td>0.864908</td>\n",
       "      <td>0.951236</td>\n",
       "      <td>0.920328</td>\n",
       "      <td>0.893865</td>\n",
       "      <td>0.865396</td>\n",
       "      <td>0.915438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97092 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ret_F1    ret_F2    ret_F3    ret_F4    rsk_F1    rsk_F2    rsk_F3  \\\n",
       "66083  0.171939  0.270738  0.394526  0.273058  0.143839  0.196426  0.141295   \n",
       "39709  0.475044  0.489305  0.311326  0.251790  0.384417  0.194289  0.192601   \n",
       "88178  0.363362  0.257881  0.375526  0.381995  0.179756  0.181495  0.213341   \n",
       "29905  0.200433  0.320284  0.381995  0.310304  0.137747  0.178042  0.182803   \n",
       "68162  0.245617  0.489305  0.212685  0.175012  0.182380  0.194289  0.129613   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "92959  0.294656  0.257881  0.318545  0.314083  0.195730  0.181495  0.144882   \n",
       "75337  0.318315  0.244021  0.314083  0.230774  0.312862  0.194807  0.159112   \n",
       "2418   1.080724  0.433474  0.168252  0.611184  0.400353  0.155556  0.196828   \n",
       "85916  0.261629  0.263809  0.240980  0.218185  0.166025  0.147950  0.183468   \n",
       "68625  0.245617  0.379804  0.239856  0.264161  0.182380  0.193074  0.172665   \n",
       "\n",
       "         rsk_F4  CORR_F1F2  CORR_F1F3  CORR_F1F4  CORR_F2F3  CORR_F2F4  \\\n",
       "66083  0.129794   0.827951   0.729154   0.692460   0.773838   0.716855   \n",
       "39709  0.198278   0.727292   0.766216   0.756955   0.838467   0.819654   \n",
       "88178  0.145330   0.894073   0.736210   0.818167   0.736360   0.862172   \n",
       "29905  0.221800   0.919326   0.892861   0.796780   0.949429   0.868108   \n",
       "68162  0.143440   0.847846   0.897266   0.920668   0.805347   0.812089   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "92959  0.159112   0.902889   0.898130   0.898642   0.903643   0.877912   \n",
       "75337  0.205234   0.767546   0.774393   0.779156   0.882857   0.817841   \n",
       "2418   0.132727   0.616322   0.587333   0.560948   0.734766   0.638158   \n",
       "85916  0.166329   0.939175   0.949920   0.943013   0.922402   0.903907   \n",
       "68625  0.196398   0.864908   0.951236   0.920328   0.893865   0.865396   \n",
       "\n",
       "       CORR_F3F4  \n",
       "66083   0.712572  \n",
       "39709   0.928007  \n",
       "88178   0.696347  \n",
       "29905   0.906294  \n",
       "68162   0.927220  \n",
       "...          ...  \n",
       "92959   0.904116  \n",
       "75337   0.827642  \n",
       "2418    0.615747  \n",
       "85916   0.955173  \n",
       "68625   0.915438  \n",
       "\n",
       "[97092 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2° window training inputs (2016 to 2021)\n",
    "dic_train[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e623c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_F1</th>\n",
       "      <th>w_F2</th>\n",
       "      <th>w_F3</th>\n",
       "      <th>w_F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66083</th>\n",
       "      <td>0.03668</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.74776</td>\n",
       "      <td>0.21556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39709</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.54199</td>\n",
       "      <td>0.45801</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88178</th>\n",
       "      <td>0.09760</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.90240</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29905</th>\n",
       "      <td>0.40062</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.59938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68162</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92959</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75337</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01841</td>\n",
       "      <td>0.98159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85916</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68625</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.92703</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97092 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          w_F1     w_F2     w_F3     w_F4\n",
       "66083  0.03668  0.00000  0.74776  0.21556\n",
       "39709  0.00000  0.54199  0.45801  0.00000\n",
       "88178  0.09760  0.00000  0.90240  0.00000\n",
       "29905  0.40062  0.00000  0.00000  0.59938\n",
       "68162  0.00000  0.00000  0.00000  1.00000\n",
       "...        ...      ...      ...      ...\n",
       "92959  1.00000  0.00000  0.00000  0.00000\n",
       "75337  0.00000  0.00000  0.00000  1.00000\n",
       "2418   0.00000  0.00000  0.01841  0.98159\n",
       "85916  0.00000  1.00000  0.00000  0.00000\n",
       "68625  0.00000  0.92703  0.00000  0.07297\n",
       "\n",
       "[97092 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2° window training targets (2016 to 2021)\n",
    "dic_train[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcc5694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ret_F1</th>\n",
       "      <th>ret_F2</th>\n",
       "      <th>ret_F3</th>\n",
       "      <th>ret_F4</th>\n",
       "      <th>rsk_F1</th>\n",
       "      <th>rsk_F2</th>\n",
       "      <th>rsk_F3</th>\n",
       "      <th>rsk_F4</th>\n",
       "      <th>CORR_F1F2</th>\n",
       "      <th>CORR_F1F3</th>\n",
       "      <th>CORR_F1F4</th>\n",
       "      <th>CORR_F2F3</th>\n",
       "      <th>CORR_F2F4</th>\n",
       "      <th>CORR_F3F4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27010</th>\n",
       "      <td>0.303668</td>\n",
       "      <td>0.271785</td>\n",
       "      <td>0.381995</td>\n",
       "      <td>0.406781</td>\n",
       "      <td>0.153158</td>\n",
       "      <td>0.183402</td>\n",
       "      <td>0.182803</td>\n",
       "      <td>0.195840</td>\n",
       "      <td>0.937055</td>\n",
       "      <td>0.951249</td>\n",
       "      <td>0.914703</td>\n",
       "      <td>0.956369</td>\n",
       "      <td>0.929685</td>\n",
       "      <td>0.945771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>1.080724</td>\n",
       "      <td>0.433474</td>\n",
       "      <td>0.200433</td>\n",
       "      <td>0.310304</td>\n",
       "      <td>0.400353</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.137747</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.616322</td>\n",
       "      <td>0.638677</td>\n",
       "      <td>0.626298</td>\n",
       "      <td>0.745024</td>\n",
       "      <td>0.749633</td>\n",
       "      <td>0.796780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87926</th>\n",
       "      <td>0.363362</td>\n",
       "      <td>0.294656</td>\n",
       "      <td>0.334630</td>\n",
       "      <td>0.325760</td>\n",
       "      <td>0.179756</td>\n",
       "      <td>0.195730</td>\n",
       "      <td>0.188213</td>\n",
       "      <td>0.154691</td>\n",
       "      <td>0.883020</td>\n",
       "      <td>0.911491</td>\n",
       "      <td>0.882312</td>\n",
       "      <td>0.942374</td>\n",
       "      <td>0.906812</td>\n",
       "      <td>0.925820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12275</th>\n",
       "      <td>0.169064</td>\n",
       "      <td>0.246350</td>\n",
       "      <td>0.433474</td>\n",
       "      <td>0.320284</td>\n",
       "      <td>0.153151</td>\n",
       "      <td>0.123095</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.178042</td>\n",
       "      <td>0.768981</td>\n",
       "      <td>0.768350</td>\n",
       "      <td>0.879922</td>\n",
       "      <td>0.756725</td>\n",
       "      <td>0.884654</td>\n",
       "      <td>0.791458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63921</th>\n",
       "      <td>0.237258</td>\n",
       "      <td>0.489305</td>\n",
       "      <td>0.293444</td>\n",
       "      <td>0.253873</td>\n",
       "      <td>0.147235</td>\n",
       "      <td>0.194289</td>\n",
       "      <td>0.219392</td>\n",
       "      <td>0.201845</td>\n",
       "      <td>0.830951</td>\n",
       "      <td>0.844052</td>\n",
       "      <td>0.890913</td>\n",
       "      <td>0.854635</td>\n",
       "      <td>0.836828</td>\n",
       "      <td>0.897772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67535</th>\n",
       "      <td>0.270738</td>\n",
       "      <td>0.222538</td>\n",
       "      <td>0.251790</td>\n",
       "      <td>0.210456</td>\n",
       "      <td>0.196426</td>\n",
       "      <td>0.152728</td>\n",
       "      <td>0.198278</td>\n",
       "      <td>0.184630</td>\n",
       "      <td>0.876043</td>\n",
       "      <td>0.867968</td>\n",
       "      <td>0.897305</td>\n",
       "      <td>0.898244</td>\n",
       "      <td>0.923962</td>\n",
       "      <td>0.936867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34646</th>\n",
       "      <td>0.326419</td>\n",
       "      <td>0.173203</td>\n",
       "      <td>0.611184</td>\n",
       "      <td>0.381995</td>\n",
       "      <td>0.168608</td>\n",
       "      <td>0.068897</td>\n",
       "      <td>0.132727</td>\n",
       "      <td>0.182803</td>\n",
       "      <td>0.545960</td>\n",
       "      <td>0.663229</td>\n",
       "      <td>0.928713</td>\n",
       "      <td>0.353593</td>\n",
       "      <td>0.519026</td>\n",
       "      <td>0.700075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104149</th>\n",
       "      <td>0.240980</td>\n",
       "      <td>0.375526</td>\n",
       "      <td>0.314083</td>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.183468</td>\n",
       "      <td>0.213341</td>\n",
       "      <td>0.159112</td>\n",
       "      <td>0.166329</td>\n",
       "      <td>0.735838</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>0.955173</td>\n",
       "      <td>0.695143</td>\n",
       "      <td>0.708400</td>\n",
       "      <td>0.906779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91972</th>\n",
       "      <td>0.367576</td>\n",
       "      <td>0.240980</td>\n",
       "      <td>0.342705</td>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.192908</td>\n",
       "      <td>0.183468</td>\n",
       "      <td>0.191335</td>\n",
       "      <td>0.166329</td>\n",
       "      <td>0.912317</td>\n",
       "      <td>0.803734</td>\n",
       "      <td>0.875501</td>\n",
       "      <td>0.851291</td>\n",
       "      <td>0.955173</td>\n",
       "      <td>0.835866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98907</th>\n",
       "      <td>0.326864</td>\n",
       "      <td>0.321232</td>\n",
       "      <td>0.297019</td>\n",
       "      <td>0.218185</td>\n",
       "      <td>0.150141</td>\n",
       "      <td>0.181495</td>\n",
       "      <td>0.183627</td>\n",
       "      <td>0.166329</td>\n",
       "      <td>0.919882</td>\n",
       "      <td>0.921081</td>\n",
       "      <td>0.885373</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.960580</td>\n",
       "      <td>0.926385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10788 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ret_F1    ret_F2    ret_F3    ret_F4    rsk_F1    rsk_F2    rsk_F3  \\\n",
       "27010   0.303668  0.271785  0.381995  0.406781  0.153158  0.183402  0.182803   \n",
       "2257    1.080724  0.433474  0.200433  0.310304  0.400353  0.155556  0.137747   \n",
       "87926   0.363362  0.294656  0.334630  0.325760  0.179756  0.195730  0.188213   \n",
       "12275   0.169064  0.246350  0.433474  0.320284  0.153151  0.123095  0.155556   \n",
       "63921   0.237258  0.489305  0.293444  0.253873  0.147235  0.194289  0.219392   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "67535   0.270738  0.222538  0.251790  0.210456  0.196426  0.152728  0.198278   \n",
       "34646   0.326419  0.173203  0.611184  0.381995  0.168608  0.068897  0.132727   \n",
       "104149  0.240980  0.375526  0.314083  0.218185  0.183468  0.213341  0.159112   \n",
       "91972   0.367576  0.240980  0.342705  0.218185  0.192908  0.183468  0.191335   \n",
       "98907   0.326864  0.321232  0.297019  0.218185  0.150141  0.181495  0.183627   \n",
       "\n",
       "          rsk_F4  CORR_F1F2  CORR_F1F3  CORR_F1F4  CORR_F2F3  CORR_F2F4  \\\n",
       "27010   0.195840   0.937055   0.951249   0.914703   0.956369   0.929685   \n",
       "2257    0.221800   0.616322   0.638677   0.626298   0.745024   0.749633   \n",
       "87926   0.154691   0.883020   0.911491   0.882312   0.942374   0.906812   \n",
       "12275   0.178042   0.768981   0.768350   0.879922   0.756725   0.884654   \n",
       "63921   0.201845   0.830951   0.844052   0.890913   0.854635   0.836828   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "67535   0.184630   0.876043   0.867968   0.897305   0.898244   0.923962   \n",
       "34646   0.182803   0.545960   0.663229   0.928713   0.353593   0.519026   \n",
       "104149  0.166329   0.735838   0.919913   0.955173   0.695143   0.708400   \n",
       "91972   0.166329   0.912317   0.803734   0.875501   0.851291   0.955173   \n",
       "98907   0.166329   0.919882   0.921081   0.885373   0.954000   0.960580   \n",
       "\n",
       "        CORR_F3F4  \n",
       "27010    0.945771  \n",
       "2257     0.796780  \n",
       "87926    0.925820  \n",
       "12275    0.791458  \n",
       "63921    0.897772  \n",
       "...           ...  \n",
       "67535    0.936867  \n",
       "34646    0.700075  \n",
       "104149   0.906779  \n",
       "91972    0.835866  \n",
       "98907    0.926385  \n",
       "\n",
       "[10788 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2° window validation inputs (2016 to 2021)\n",
    "dic_val[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c20f958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Alaska Black FIC FIA BDR Nível I', 'Apex Ações 30 FIC FIA', 'ARX Income FIC FIA', 'Atlas One FIC FIA'], ['Alaska Black FIC FIA BDR Nível I', 'Apex Ações 30 FIC FIA', 'ARX Income FIC FIA', 'Atmos Ações FIC FIA'], ['Alaska Black FIC FIA BDR Nível I', 'Apex Ações 30 FIC FIA', 'ARX Income FIC FIA', 'AZ Quest Small Mid Caps FIC FIA'], ['Alaska Black FIC FIA BDR Nível I', 'Apex Ações 30 FIC FIA', 'ARX Income FIC FIA', 'Bahia AM Smid Caps Valor FIC FIA'], ['Alaska Black FIC FIA BDR Nível I', 'Apex Ações 30 FIC FIA', 'ARX Income FIC FIA', 'BNP Paribas Small Caps FIA']]\n",
      "35960\n"
     ]
    }
   ],
   "source": [
    "print(pred_port_list[:5])\n",
    "print(len(pred_port_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef197a",
   "metadata": {},
   "source": [
    "## Inputs scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952431c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling training, validation as prediction inputs\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "dic_train_prep = {}\n",
    "dic_val_prep = {}\n",
    "dic_pred_prep = {}\n",
    "\n",
    "for w in dic_train.keys():\n",
    "    \n",
    "    X_train_prepared = minmax_scaler.fit_transform(dic_train[w][0])\n",
    "    X_val_prepared = minmax_scaler.transform(dic_val[w][0])\n",
    "    X_pred_prepared = minmax_scaler.transform(dic_pred[w])\n",
    "\n",
    "    dic_train_prep[w] = [X_train_prepared, dic_train[w][1].values]\n",
    "    dic_val_prep[w] = [X_val_prepared, dic_val[w][1].values]\n",
    "    dic_pred_prep[w] = [X_pred_prepared, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee6f42dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19707415, 0.34700268, 0.48046341, ..., 0.68545949, 0.59251392,\n",
       "        0.59050215],\n",
       "       [0.46487261, 0.58264722, 0.39076242, ..., 0.79087588, 0.76019014,\n",
       "        0.94488175],\n",
       "       [0.36619927, 0.33314106, 0.45997805, ..., 0.62432819, 0.82954028,\n",
       "        0.56381236],\n",
       "       ...,\n",
       "       [1.        , 0.52245407, 0.23650929, ..., 0.6217295 , 0.46415285,\n",
       "        0.43122956],\n",
       "       [0.27631706, 0.33953279, 0.31492   , ..., 0.92778146, 0.89761452,\n",
       "        0.98956781],\n",
       "       [0.26217025, 0.46459102, 0.31370778, ..., 0.88123395, 0.83479804,\n",
       "        0.92420606]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2° window scaled training inputs janela (2016 a 2021)\n",
    "dic_train_prep[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01bd155",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f35c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model():\n",
    "    \n",
    "    # build Neural Networks model and architeture: 14 (inputs) -> 3 x 20 layers -> 4 (outputs)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.Input(shape = (dic_train_prep[0][0].shape[1],)))\n",
    "    model.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(20, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(4, activation = \"softmax\"))\n",
    "    \n",
    "    # compile the model\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    # opt = tf.keras.optimizers.SGD(learning_rate = 0.1)\n",
    "    model.compile(optimizer = opt, loss = \"mse\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec5c8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training window:  0\n",
      "Epoch 1/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.1216 - val_loss: 0.1097\n",
      "Epoch 2/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.1065 - val_loss: 0.1013\n",
      "Epoch 3/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1007 - val_loss: 0.0968\n",
      "Epoch 4/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0963 - val_loss: 0.0930\n",
      "Epoch 5/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0920 - val_loss: 0.0896\n",
      "Epoch 6/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0888 - val_loss: 0.0870\n",
      "Epoch 7/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0864 - val_loss: 0.0859\n",
      "Epoch 8/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0844 - val_loss: 0.0823\n",
      "Epoch 9/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0829 - val_loss: 0.0852\n",
      "Epoch 10/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0817 - val_loss: 0.0800\n",
      "Epoch 11/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0805 - val_loss: 0.0789\n",
      "Epoch 12/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0794 - val_loss: 0.0775\n",
      "Epoch 13/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0782 - val_loss: 0.0784\n",
      "Epoch 14/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0772 - val_loss: 0.0791\n",
      "Epoch 15/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0761 - val_loss: 0.0772\n",
      "Epoch 16/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0751 - val_loss: 0.0739\n",
      "Epoch 17/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0739 - val_loss: 0.0754\n",
      "Epoch 18/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0727 - val_loss: 0.0725\n",
      "Epoch 19/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0722 - val_loss: 0.0714\n",
      "Epoch 20/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0714 - val_loss: 0.0704\n",
      "Epoch 21/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0707 - val_loss: 0.0728\n",
      "Epoch 22/600\n",
      "3035/3035 [==============================] - 13s 4ms/step - loss: 0.0704 - val_loss: 0.0702\n",
      "Epoch 23/600\n",
      "3035/3035 [==============================] - 13s 4ms/step - loss: 0.0699 - val_loss: 0.0734\n",
      "Epoch 24/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0693 - val_loss: 0.0718\n",
      "Epoch 25/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0689 - val_loss: 0.0682\n",
      "Epoch 26/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0686 - val_loss: 0.0681\n",
      "Epoch 27/600\n",
      "3035/3035 [==============================] - 13s 4ms/step - loss: 0.0679 - val_loss: 0.0695\n",
      "Epoch 28/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0677 - val_loss: 0.0685\n",
      "Epoch 29/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0673 - val_loss: 0.0684\n",
      "Epoch 30/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0670 - val_loss: 0.0679\n",
      "Epoch 31/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0667 - val_loss: 0.0667\n",
      "Epoch 32/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0663 - val_loss: 0.0693\n",
      "Epoch 33/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0661 - val_loss: 0.0678\n",
      "Epoch 34/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0662 - val_loss: 0.0660\n",
      "Epoch 35/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0656 - val_loss: 0.0652\n",
      "Epoch 36/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0654 - val_loss: 0.0648\n",
      "Epoch 37/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0651 - val_loss: 0.0663\n",
      "Epoch 38/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0650 - val_loss: 0.0647\n",
      "Epoch 39/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0647 - val_loss: 0.0686\n",
      "Epoch 40/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0646 - val_loss: 0.0646\n",
      "Epoch 41/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0645 - val_loss: 0.0652\n",
      "Epoch 42/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0642 - val_loss: 0.0657\n",
      "Epoch 43/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0642 - val_loss: 0.0647\n",
      "Epoch 44/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0637 - val_loss: 0.0652\n",
      "Epoch 45/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0636 - val_loss: 0.0649\n",
      "Epoch 46/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0635 - val_loss: 0.0636\n",
      "Epoch 47/600\n",
      "3035/3035 [==============================] - 13s 4ms/step - loss: 0.0633 - val_loss: 0.0677\n",
      "Epoch 48/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0632 - val_loss: 0.0626\n",
      "Epoch 49/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0631 - val_loss: 0.0662\n",
      "Epoch 50/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0629 - val_loss: 0.0667\n",
      "Epoch 51/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0628 - val_loss: 0.0653\n",
      "Epoch 52/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0626 - val_loss: 0.0668\n",
      "Epoch 53/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0625 - val_loss: 0.0616\n",
      "Epoch 54/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0622 - val_loss: 0.0655\n",
      "Epoch 55/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0621 - val_loss: 0.0626\n",
      "Epoch 56/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0622 - val_loss: 0.0620\n",
      "Epoch 57/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0619 - val_loss: 0.0625\n",
      "Epoch 58/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0618 - val_loss: 0.0636\n",
      "Epoch 59/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0618 - val_loss: 0.0633\n",
      "Epoch 60/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0615 - val_loss: 0.0616\n",
      "Epoch 61/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0614 - val_loss: 0.0638\n",
      "Epoch 62/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0611 - val_loss: 0.0631\n",
      "Epoch 63/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0613 - val_loss: 0.0641\n",
      "Epoch 64/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0610 - val_loss: 0.0624\n",
      "Epoch 65/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0608 - val_loss: 0.0635\n",
      "Epoch 66/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0608 - val_loss: 0.0644\n",
      "Epoch 67/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0605 - val_loss: 0.0626\n",
      "Epoch 68/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0605 - val_loss: 0.0609\n",
      "Epoch 69/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0604 - val_loss: 0.0624\n",
      "Epoch 70/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 71/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0602 - val_loss: 0.0619\n",
      "Epoch 72/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0603 - val_loss: 0.0606\n",
      "Epoch 73/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0600 - val_loss: 0.0698\n",
      "Epoch 74/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0601 - val_loss: 0.0623\n",
      "Epoch 75/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0598 - val_loss: 0.0635\n",
      "Epoch 76/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0600 - val_loss: 0.0612\n",
      "Epoch 77/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0595 - val_loss: 0.0607\n",
      "Epoch 78/600\n",
      "3035/3035 [==============================] - 14s 5ms/step - loss: 0.0595 - val_loss: 0.0620\n",
      "Epoch 79/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0595 - val_loss: 0.0615\n",
      "Epoch 80/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0595 - val_loss: 0.0590\n",
      "Epoch 81/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0593 - val_loss: 0.0597\n",
      "Epoch 82/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0592 - val_loss: 0.0583\n",
      "Epoch 83/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0591 - val_loss: 0.0610\n",
      "Epoch 84/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0591 - val_loss: 0.0622\n",
      "Epoch 85/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0588 - val_loss: 0.0584\n",
      "Epoch 86/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0586 - val_loss: 0.0585\n",
      "Epoch 87/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0586 - val_loss: 0.0594\n",
      "Epoch 88/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0585 - val_loss: 0.0589\n",
      "Epoch 89/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0582 - val_loss: 0.0597\n",
      "Epoch 90/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0583 - val_loss: 0.0577\n",
      "Epoch 91/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0581 - val_loss: 0.0583\n",
      "Epoch 92/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0581 - val_loss: 0.0592\n",
      "Epoch 93/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0581 - val_loss: 0.0635\n",
      "Epoch 94/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0580 - val_loss: 0.0587\n",
      "Epoch 95/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0577 - val_loss: 0.0585\n",
      "Epoch 96/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0576 - val_loss: 0.0588\n",
      "Epoch 97/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0576 - val_loss: 0.0585\n",
      "Epoch 98/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0574 - val_loss: 0.0580\n",
      "Epoch 99/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0574 - val_loss: 0.0586\n",
      "Epoch 100/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0571 - val_loss: 0.0587\n",
      "Epoch 101/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0571 - val_loss: 0.0572\n",
      "Epoch 102/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0572 - val_loss: 0.0567\n",
      "Epoch 103/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0570 - val_loss: 0.0604\n",
      "Epoch 104/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0569 - val_loss: 0.0567\n",
      "Epoch 105/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0569 - val_loss: 0.0577\n",
      "Epoch 106/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0567 - val_loss: 0.0592\n",
      "Epoch 107/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0565 - val_loss: 0.0593\n",
      "Epoch 108/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0567 - val_loss: 0.0563\n",
      "Epoch 109/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0565 - val_loss: 0.0575\n",
      "Epoch 110/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0564 - val_loss: 0.0570\n",
      "Epoch 111/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0564 - val_loss: 0.0562\n",
      "Epoch 112/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0563 - val_loss: 0.0580\n",
      "Epoch 113/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0563 - val_loss: 0.0572\n",
      "Epoch 114/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0561 - val_loss: 0.0585\n",
      "Epoch 115/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0559 - val_loss: 0.0579\n",
      "Epoch 116/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0559 - val_loss: 0.0569\n",
      "Epoch 117/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0560 - val_loss: 0.0569\n",
      "Epoch 118/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0558 - val_loss: 0.0564\n",
      "Epoch 119/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0558 - val_loss: 0.0564\n",
      "Epoch 120/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0558 - val_loss: 0.0561\n",
      "Epoch 121/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0556 - val_loss: 0.0571\n",
      "Epoch 122/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0556 - val_loss: 0.0551\n",
      "Epoch 123/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0556 - val_loss: 0.0562\n",
      "Epoch 124/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0555 - val_loss: 0.0571\n",
      "Epoch 125/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0555 - val_loss: 0.0587\n",
      "Epoch 126/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0556 - val_loss: 0.0590\n",
      "Epoch 127/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0555 - val_loss: 0.0562\n",
      "Epoch 128/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0555 - val_loss: 0.0556\n",
      "Epoch 129/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0552 - val_loss: 0.0547\n",
      "Epoch 130/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0553 - val_loss: 0.0566\n",
      "Epoch 131/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0551 - val_loss: 0.0578\n",
      "Epoch 132/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0552 - val_loss: 0.0568\n",
      "Epoch 133/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0552 - val_loss: 0.0560\n",
      "Epoch 134/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0550 - val_loss: 0.0560\n",
      "Epoch 135/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0551 - val_loss: 0.0568\n",
      "Epoch 136/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0550 - val_loss: 0.0547\n",
      "Epoch 137/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0550 - val_loss: 0.0569\n",
      "Epoch 138/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "Epoch 139/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0549 - val_loss: 0.0561\n",
      "Epoch 140/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0548 - val_loss: 0.0555\n",
      "Epoch 141/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0548 - val_loss: 0.0589\n",
      "Epoch 142/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0548 - val_loss: 0.0544\n",
      "Epoch 143/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0547 - val_loss: 0.0550\n",
      "Epoch 144/600\n",
      "3035/3035 [==============================] - 14s 5ms/step - loss: 0.0546 - val_loss: 0.0563\n",
      "Epoch 145/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0548 - val_loss: 0.0568\n",
      "Epoch 146/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0547 - val_loss: 0.0568\n",
      "Epoch 147/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0547 - val_loss: 0.0550\n",
      "Epoch 148/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0544 - val_loss: 0.0548\n",
      "Epoch 149/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0546 - val_loss: 0.0540\n",
      "Epoch 150/600\n",
      "3035/3035 [==============================] - 12s 4ms/step - loss: 0.0544 - val_loss: 0.0544\n",
      "Epoch 151/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0546 - val_loss: 0.0558\n",
      "Epoch 152/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0543 - val_loss: 0.0571\n",
      "Epoch 153/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0543 - val_loss: 0.0552\n",
      "Epoch 154/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0544 - val_loss: 0.0533\n",
      "Epoch 155/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0543 - val_loss: 0.0585\n",
      "Epoch 156/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0543 - val_loss: 0.0561\n",
      "Epoch 157/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0542 - val_loss: 0.0542\n",
      "Epoch 158/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0543 - val_loss: 0.0547\n",
      "Epoch 159/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0540 - val_loss: 0.0593\n",
      "Epoch 160/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0541 - val_loss: 0.0566\n",
      "Epoch 161/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0540 - val_loss: 0.0565\n",
      "Epoch 162/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0540 - val_loss: 0.0552\n",
      "Epoch 163/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0539 - val_loss: 0.0533\n",
      "Epoch 164/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0539 - val_loss: 0.0536\n",
      "Epoch 165/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0538 - val_loss: 0.0540\n",
      "Epoch 166/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0539 - val_loss: 0.0548\n",
      "Epoch 167/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0537 - val_loss: 0.0546\n",
      "Epoch 168/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0536 - val_loss: 0.0544\n",
      "Epoch 169/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0538 - val_loss: 0.0543\n",
      "Epoch 170/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0534 - val_loss: 0.0552\n",
      "Epoch 171/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0535 - val_loss: 0.0533\n",
      "Epoch 172/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0534 - val_loss: 0.0531\n",
      "Epoch 173/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0532 - val_loss: 0.0539\n",
      "Epoch 174/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0535 - val_loss: 0.0587\n",
      "Epoch 175/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0531 - val_loss: 0.0546\n",
      "Epoch 176/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0530 - val_loss: 0.0548\n",
      "Epoch 177/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0531 - val_loss: 0.0533\n",
      "Epoch 178/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0530 - val_loss: 0.0553\n",
      "Epoch 179/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0529 - val_loss: 0.0541\n",
      "Epoch 180/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0527 - val_loss: 0.0535\n",
      "Epoch 181/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0528 - val_loss: 0.0553\n",
      "Epoch 182/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0528 - val_loss: 0.0529\n",
      "Epoch 183/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0526 - val_loss: 0.0534\n",
      "Epoch 184/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0526 - val_loss: 0.0546\n",
      "Epoch 185/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0524 - val_loss: 0.0542\n",
      "Epoch 186/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0523 - val_loss: 0.0517\n",
      "Epoch 187/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0524 - val_loss: 0.0521\n",
      "Epoch 188/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0522 - val_loss: 0.0517\n",
      "Epoch 189/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0523 - val_loss: 0.0552\n",
      "Epoch 190/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0522 - val_loss: 0.0538\n",
      "Epoch 191/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0521 - val_loss: 0.0542\n",
      "Epoch 192/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0521 - val_loss: 0.0509\n",
      "Epoch 193/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0521 - val_loss: 0.0533\n",
      "Epoch 194/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0518 - val_loss: 0.0508\n",
      "Epoch 195/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0517 - val_loss: 0.0503\n",
      "Epoch 196/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0519 - val_loss: 0.0541\n",
      "Epoch 197/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0518 - val_loss: 0.0524\n",
      "Epoch 198/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0517 - val_loss: 0.0530\n",
      "Epoch 199/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0516 - val_loss: 0.0534\n",
      "Epoch 200/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0516 - val_loss: 0.0503\n",
      "Epoch 201/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0517 - val_loss: 0.0511\n",
      "Epoch 202/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0516 - val_loss: 0.0531\n",
      "Epoch 203/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0516 - val_loss: 0.0551\n",
      "Epoch 204/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0514 - val_loss: 0.0504\n",
      "Epoch 205/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0516 - val_loss: 0.0521\n",
      "Epoch 206/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0514 - val_loss: 0.0504\n",
      "Epoch 207/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0514 - val_loss: 0.0523\n",
      "Epoch 208/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0515 - val_loss: 0.0553\n",
      "Epoch 209/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0513 - val_loss: 0.0550\n",
      "Epoch 210/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0513 - val_loss: 0.0519\n",
      "Epoch 211/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0511 - val_loss: 0.0516\n",
      "Epoch 212/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0510 - val_loss: 0.0517\n",
      "Epoch 213/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0510 - val_loss: 0.0525\n",
      "Epoch 214/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0510 - val_loss: 0.0502\n",
      "Epoch 215/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0510 - val_loss: 0.0511\n",
      "Epoch 216/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0511 - val_loss: 0.0519\n",
      "Epoch 217/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0508 - val_loss: 0.0514\n",
      "Epoch 218/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0508 - val_loss: 0.0505\n",
      "Epoch 219/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0509 - val_loss: 0.0524\n",
      "Epoch 220/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0509 - val_loss: 0.0526\n",
      "Epoch 221/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0507 - val_loss: 0.0509\n",
      "Epoch 222/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0508 - val_loss: 0.0527\n",
      "Epoch 223/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0508 - val_loss: 0.0531\n",
      "Epoch 224/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 225/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0506 - val_loss: 0.0532\n",
      "Epoch 226/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0503 - val_loss: 0.0509\n",
      "Epoch 227/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0502 - val_loss: 0.0499\n",
      "Epoch 228/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0502 - val_loss: 0.0497\n",
      "Epoch 229/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0499 - val_loss: 0.0506\n",
      "Epoch 230/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0501 - val_loss: 0.0526\n",
      "Epoch 231/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0500 - val_loss: 0.0511\n",
      "Epoch 232/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0498 - val_loss: 0.0508\n",
      "Epoch 233/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0498 - val_loss: 0.0493\n",
      "Epoch 234/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0497 - val_loss: 0.0539\n",
      "Epoch 235/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0496 - val_loss: 0.0505\n",
      "Epoch 236/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0495 - val_loss: 0.0482\n",
      "Epoch 237/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0494 - val_loss: 0.0501\n",
      "Epoch 238/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0493 - val_loss: 0.0497\n",
      "Epoch 239/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0493 - val_loss: 0.0538\n",
      "Epoch 240/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0493 - val_loss: 0.0502\n",
      "Epoch 241/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0491 - val_loss: 0.0483\n",
      "Epoch 242/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0491 - val_loss: 0.0487\n",
      "Epoch 243/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0490 - val_loss: 0.0486\n",
      "Epoch 244/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0490 - val_loss: 0.0496\n",
      "Epoch 245/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0490 - val_loss: 0.0480\n",
      "Epoch 246/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0488 - val_loss: 0.0509\n",
      "Epoch 247/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0488 - val_loss: 0.0479\n",
      "Epoch 248/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0490 - val_loss: 0.0560\n",
      "Epoch 249/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0489 - val_loss: 0.0505\n",
      "Epoch 250/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0487 - val_loss: 0.0478\n",
      "Epoch 251/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0487 - val_loss: 0.0482\n",
      "Epoch 252/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0486 - val_loss: 0.0473\n",
      "Epoch 253/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0484 - val_loss: 0.0487\n",
      "Epoch 254/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0485 - val_loss: 0.0502\n",
      "Epoch 255/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0486 - val_loss: 0.0493\n",
      "Epoch 256/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0485 - val_loss: 0.0496\n",
      "Epoch 257/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0485 - val_loss: 0.0515\n",
      "Epoch 258/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0483 - val_loss: 0.0482\n",
      "Epoch 259/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0484 - val_loss: 0.0493\n",
      "Epoch 260/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0482 - val_loss: 0.0496\n",
      "Epoch 261/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0484 - val_loss: 0.0482\n",
      "Epoch 262/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0484 - val_loss: 0.0467\n",
      "Epoch 263/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0482 - val_loss: 0.0481\n",
      "Epoch 264/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0482 - val_loss: 0.0479\n",
      "Epoch 265/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0482 - val_loss: 0.0491\n",
      "Epoch 266/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0481 - val_loss: 0.0481\n",
      "Epoch 267/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0480 - val_loss: 0.0480\n",
      "Epoch 268/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0480 - val_loss: 0.0473\n",
      "Epoch 269/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0480 - val_loss: 0.0505\n",
      "Epoch 270/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0479 - val_loss: 0.0474\n",
      "Epoch 271/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0478 - val_loss: 0.0476\n",
      "Epoch 272/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0478 - val_loss: 0.0477\n",
      "Epoch 273/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0478 - val_loss: 0.0483\n",
      "Epoch 274/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0479 - val_loss: 0.0475\n",
      "Epoch 275/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0476 - val_loss: 0.0483\n",
      "Epoch 276/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0480 - val_loss: 0.0457\n",
      "Epoch 277/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0478 - val_loss: 0.0477\n",
      "Epoch 278/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0476 - val_loss: 0.0471\n",
      "Epoch 279/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0479 - val_loss: 0.0490\n",
      "Epoch 280/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0476 - val_loss: 0.0484\n",
      "Epoch 281/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0478 - val_loss: 0.0513\n",
      "Epoch 282/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0477 - val_loss: 0.0467\n",
      "Epoch 283/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0476 - val_loss: 0.0460\n",
      "Epoch 284/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0474 - val_loss: 0.0503\n",
      "Epoch 285/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0475 - val_loss: 0.0467\n",
      "Epoch 286/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0475 - val_loss: 0.0477\n",
      "Epoch 287/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0474 - val_loss: 0.0483\n",
      "Epoch 288/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0474 - val_loss: 0.0470\n",
      "Epoch 289/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0474 - val_loss: 0.0461\n",
      "Epoch 290/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0473 - val_loss: 0.0477\n",
      "Epoch 291/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0473 - val_loss: 0.0486\n",
      "Epoch 292/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0473 - val_loss: 0.0460\n",
      "Epoch 293/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0471 - val_loss: 0.0477\n",
      "Epoch 294/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0471 - val_loss: 0.0465\n",
      "Epoch 295/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0473 - val_loss: 0.0477\n",
      "Epoch 296/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0473 - val_loss: 0.0475\n",
      "Epoch 297/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0471 - val_loss: 0.0486\n",
      "Epoch 298/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0471 - val_loss: 0.0499\n",
      "Epoch 299/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0470 - val_loss: 0.0465\n",
      "Epoch 300/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0469 - val_loss: 0.0479\n",
      "Epoch 301/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0470 - val_loss: 0.0465\n",
      "Epoch 302/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0469 - val_loss: 0.0473\n",
      "Epoch 303/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0469 - val_loss: 0.0466\n",
      "Epoch 304/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0467 - val_loss: 0.0477\n",
      "Epoch 305/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0469 - val_loss: 0.0478\n",
      "Epoch 306/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0469 - val_loss: 0.0464\n",
      "Epoch 307/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0467 - val_loss: 0.0473\n",
      "Epoch 308/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0465 - val_loss: 0.0455\n",
      "Epoch 309/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0468 - val_loss: 0.0452\n",
      "Epoch 310/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0465 - val_loss: 0.0466\n",
      "Epoch 311/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0466 - val_loss: 0.0477\n",
      "Epoch 312/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0466 - val_loss: 0.0459\n",
      "Epoch 313/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0465 - val_loss: 0.0458\n",
      "Epoch 314/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0464 - val_loss: 0.0461\n",
      "Epoch 315/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0464 - val_loss: 0.0458\n",
      "Epoch 316/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0465 - val_loss: 0.0463\n",
      "Epoch 317/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0463 - val_loss: 0.0463\n",
      "Epoch 318/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0463 - val_loss: 0.0452\n",
      "Epoch 319/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0463 - val_loss: 0.0460\n",
      "Epoch 320/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0463 - val_loss: 0.0459\n",
      "Epoch 321/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0461 - val_loss: 0.0460\n",
      "Epoch 322/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0462 - val_loss: 0.0470\n",
      "Epoch 323/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0462 - val_loss: 0.0471\n",
      "Epoch 324/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0462 - val_loss: 0.0447\n",
      "Epoch 325/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0460 - val_loss: 0.0475\n",
      "Epoch 326/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0460 - val_loss: 0.0473\n",
      "Epoch 327/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0458 - val_loss: 0.0464\n",
      "Epoch 328/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0460 - val_loss: 0.0479\n",
      "Epoch 329/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0459 - val_loss: 0.0494\n",
      "Epoch 330/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0460 - val_loss: 0.0448\n",
      "Epoch 331/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0458 - val_loss: 0.0487\n",
      "Epoch 332/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0460 - val_loss: 0.0477\n",
      "Epoch 333/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0457 - val_loss: 0.0461\n",
      "Epoch 334/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0457 - val_loss: 0.0459\n",
      "Epoch 335/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0455 - val_loss: 0.0454\n",
      "Epoch 336/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0456 - val_loss: 0.0452\n",
      "Epoch 337/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0456 - val_loss: 0.0445\n",
      "Epoch 338/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0455 - val_loss: 0.0488\n",
      "Epoch 339/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0457 - val_loss: 0.0461\n",
      "Epoch 340/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0455 - val_loss: 0.0451\n",
      "Epoch 341/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0454 - val_loss: 0.0451\n",
      "Epoch 342/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0454 - val_loss: 0.0447\n",
      "Epoch 343/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0456 - val_loss: 0.0440\n",
      "Epoch 344/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0453 - val_loss: 0.0455\n",
      "Epoch 345/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0453 - val_loss: 0.0456\n",
      "Epoch 346/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0452 - val_loss: 0.0442\n",
      "Epoch 347/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0454 - val_loss: 0.0456\n",
      "Epoch 348/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0452 - val_loss: 0.0438\n",
      "Epoch 349/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0452 - val_loss: 0.0433\n",
      "Epoch 350/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0450 - val_loss: 0.0465\n",
      "Epoch 351/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0451 - val_loss: 0.0468\n",
      "Epoch 352/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0449 - val_loss: 0.0460\n",
      "Epoch 353/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0449 - val_loss: 0.0448\n",
      "Epoch 354/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0452 - val_loss: 0.0465\n",
      "Epoch 355/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 356/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0447 - val_loss: 0.0445\n",
      "Epoch 357/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0449 - val_loss: 0.0463\n",
      "Epoch 358/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0450 - val_loss: 0.0447\n",
      "Epoch 359/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0447 - val_loss: 0.0486\n",
      "Epoch 360/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0448 - val_loss: 0.0455\n",
      "Epoch 361/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0449 - val_loss: 0.0438\n",
      "Epoch 362/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0446 - val_loss: 0.0441\n",
      "Epoch 363/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0449 - val_loss: 0.0452\n",
      "Epoch 364/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0447 - val_loss: 0.0447\n",
      "Epoch 365/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0445 - val_loss: 0.0455\n",
      "Epoch 366/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0446 - val_loss: 0.0448\n",
      "Epoch 367/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0445 - val_loss: 0.0437\n",
      "Epoch 368/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0445 - val_loss: 0.0466\n",
      "Epoch 369/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0445 - val_loss: 0.0469\n",
      "Epoch 370/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0444 - val_loss: 0.0430\n",
      "Epoch 371/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0444 - val_loss: 0.0451\n",
      "Epoch 372/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0443 - val_loss: 0.0452\n",
      "Epoch 373/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0444 - val_loss: 0.0448\n",
      "Epoch 374/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0443 - val_loss: 0.0457\n",
      "Epoch 375/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0443 - val_loss: 0.0458\n",
      "Epoch 376/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0444 - val_loss: 0.0467\n",
      "Epoch 377/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0443 - val_loss: 0.0475\n",
      "Epoch 378/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0443 - val_loss: 0.0442\n",
      "Epoch 379/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0441 - val_loss: 0.0433\n",
      "Epoch 380/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0441 - val_loss: 0.0445\n",
      "Epoch 381/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0442 - val_loss: 0.0455\n",
      "Epoch 382/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0443 - val_loss: 0.0439\n",
      "Epoch 383/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0441 - val_loss: 0.0437\n",
      "Epoch 384/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0441 - val_loss: 0.0466\n",
      "Epoch 385/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0442 - val_loss: 0.0453\n",
      "Epoch 386/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0439 - val_loss: 0.0430\n",
      "Epoch 387/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0441 - val_loss: 0.0451\n",
      "Epoch 388/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0440 - val_loss: 0.0443\n",
      "Epoch 389/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0437 - val_loss: 0.0432\n",
      "Epoch 390/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0439 - val_loss: 0.0449\n",
      "Epoch 391/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0437 - val_loss: 0.0461\n",
      "Epoch 392/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0440 - val_loss: 0.0433\n",
      "Epoch 393/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0438 - val_loss: 0.0444\n",
      "Epoch 394/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0438 - val_loss: 0.0448\n",
      "Epoch 395/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0437 - val_loss: 0.0430\n",
      "Epoch 396/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0436 - val_loss: 0.0433\n",
      "Epoch 397/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0436 - val_loss: 0.0417\n",
      "Epoch 398/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0436 - val_loss: 0.0442\n",
      "Epoch 399/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0435 - val_loss: 0.0443\n",
      "Epoch 400/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0435 - val_loss: 0.0451\n",
      "Epoch 401/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0435 - val_loss: 0.0435\n",
      "Epoch 402/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0434 - val_loss: 0.0456\n",
      "Epoch 403/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0434 - val_loss: 0.0437\n",
      "Epoch 404/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0434 - val_loss: 0.0444\n",
      "Epoch 405/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0434 - val_loss: 0.0449\n",
      "Epoch 406/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0433 - val_loss: 0.0466\n",
      "Epoch 407/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0434 - val_loss: 0.0451\n",
      "Epoch 408/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0431 - val_loss: 0.0427\n",
      "Epoch 409/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0433 - val_loss: 0.0433\n",
      "Epoch 410/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0433 - val_loss: 0.0441\n",
      "Epoch 411/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0433 - val_loss: 0.0460\n",
      "Epoch 412/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0433 - val_loss: 0.0443\n",
      "Epoch 413/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0434 - val_loss: 0.0439\n",
      "Epoch 414/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0431 - val_loss: 0.0415\n",
      "Epoch 415/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0431 - val_loss: 0.0423\n",
      "Epoch 416/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0431 - val_loss: 0.0455\n",
      "Epoch 417/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0431 - val_loss: 0.0442\n",
      "Epoch 418/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0434 - val_loss: 0.0442\n",
      "Epoch 419/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0432 - val_loss: 0.0451\n",
      "Epoch 420/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0432 - val_loss: 0.0428\n",
      "Epoch 421/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0430 - val_loss: 0.0433\n",
      "Epoch 422/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0428 - val_loss: 0.0421\n",
      "Epoch 423/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0431 - val_loss: 0.0440\n",
      "Epoch 424/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0430 - val_loss: 0.0429\n",
      "Epoch 425/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0431 - val_loss: 0.0427\n",
      "Epoch 426/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0430 - val_loss: 0.0429\n",
      "Epoch 427/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0429 - val_loss: 0.0424\n",
      "Epoch 428/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0430 - val_loss: 0.0428\n",
      "Epoch 429/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0429 - val_loss: 0.0443\n",
      "Epoch 430/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0429 - val_loss: 0.0448\n",
      "Epoch 431/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0428 - val_loss: 0.0421\n",
      "Epoch 432/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0430 - val_loss: 0.0470\n",
      "Epoch 433/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0428 - val_loss: 0.0456\n",
      "Epoch 434/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0430 - val_loss: 0.0429\n",
      "Epoch 435/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0428 - val_loss: 0.0430\n",
      "Epoch 436/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0427 - val_loss: 0.0420\n",
      "Epoch 437/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0427 - val_loss: 0.0424\n",
      "Epoch 438/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0426 - val_loss: 0.0432\n",
      "Epoch 439/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0427 - val_loss: 0.0417\n",
      "Epoch 440/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0427 - val_loss: 0.0429\n",
      "Epoch 441/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0425 - val_loss: 0.0423\n",
      "Epoch 442/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0425 - val_loss: 0.0424\n",
      "Epoch 443/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0425 - val_loss: 0.0455\n",
      "Epoch 444/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0428 - val_loss: 0.0421\n",
      "Epoch 445/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0425 - val_loss: 0.0424\n",
      "Epoch 446/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0426 - val_loss: 0.0445\n",
      "Epoch 447/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0424 - val_loss: 0.0419\n",
      "Epoch 448/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0424 - val_loss: 0.0408\n",
      "Epoch 449/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0425 - val_loss: 0.0417\n",
      "Epoch 450/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0423 - val_loss: 0.0441\n",
      "Epoch 451/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0425 - val_loss: 0.0447\n",
      "Epoch 452/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0423 - val_loss: 0.0421\n",
      "Epoch 453/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0423 - val_loss: 0.0439\n",
      "Epoch 454/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0423 - val_loss: 0.0439\n",
      "Epoch 455/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0421 - val_loss: 0.0433\n",
      "Epoch 456/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0422 - val_loss: 0.0413\n",
      "Epoch 457/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0421 - val_loss: 0.0427\n",
      "Epoch 458/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0422 - val_loss: 0.0416\n",
      "Epoch 459/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0422 - val_loss: 0.0445\n",
      "Epoch 460/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0421 - val_loss: 0.0445\n",
      "Epoch 461/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0420 - val_loss: 0.0438\n",
      "Epoch 462/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0420 - val_loss: 0.0425\n",
      "Epoch 463/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0419 - val_loss: 0.0427\n",
      "Epoch 464/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0420 - val_loss: 0.0416\n",
      "Epoch 465/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0418 - val_loss: 0.0450\n",
      "Epoch 466/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0418 - val_loss: 0.0414\n",
      "Epoch 467/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0419 - val_loss: 0.0426\n",
      "Epoch 468/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0418 - val_loss: 0.0445\n",
      "Epoch 469/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0418 - val_loss: 0.0417\n",
      "Epoch 470/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0417 - val_loss: 0.0418\n",
      "Epoch 471/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0417 - val_loss: 0.0407\n",
      "Epoch 472/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0417 - val_loss: 0.0431\n",
      "Epoch 473/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0417 - val_loss: 0.0412\n",
      "Epoch 474/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0414 - val_loss: 0.0414\n",
      "Epoch 475/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0417 - val_loss: 0.0410\n",
      "Epoch 476/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0415 - val_loss: 0.0414\n",
      "Epoch 477/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0416 - val_loss: 0.0408\n",
      "Epoch 478/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0415 - val_loss: 0.0396\n",
      "Epoch 479/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0413 - val_loss: 0.0414\n",
      "Epoch 480/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0413 - val_loss: 0.0408\n",
      "Epoch 481/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0413 - val_loss: 0.0408\n",
      "Epoch 482/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0413 - val_loss: 0.0395\n",
      "Epoch 483/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0412 - val_loss: 0.0408\n",
      "Epoch 484/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0413 - val_loss: 0.0413\n",
      "Epoch 485/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0411 - val_loss: 0.0405\n",
      "Epoch 486/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0411 - val_loss: 0.0437\n",
      "Epoch 487/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0412 - val_loss: 0.0417\n",
      "Epoch 488/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0410 - val_loss: 0.0398\n",
      "Epoch 489/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0409 - val_loss: 0.0390\n",
      "Epoch 490/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0410 - val_loss: 0.0403\n",
      "Epoch 491/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0408 - val_loss: 0.0401\n",
      "Epoch 492/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0406 - val_loss: 0.0398\n",
      "Epoch 493/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0408 - val_loss: 0.0401\n",
      "Epoch 494/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0405 - val_loss: 0.0415\n",
      "Epoch 495/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0405 - val_loss: 0.0423\n",
      "Epoch 496/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0405 - val_loss: 0.0397\n",
      "Epoch 497/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0405 - val_loss: 0.0397\n",
      "Epoch 498/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0404 - val_loss: 0.0405\n",
      "Epoch 499/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0405 - val_loss: 0.0388\n",
      "Epoch 500/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0401 - val_loss: 0.0437\n",
      "Epoch 501/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0403 - val_loss: 0.0404\n",
      "Epoch 502/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0403 - val_loss: 0.0401\n",
      "Epoch 503/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0402 - val_loss: 0.0402\n",
      "Epoch 504/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0402 - val_loss: 0.0387\n",
      "Epoch 505/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0399 - val_loss: 0.0394\n",
      "Epoch 506/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0398 - val_loss: 0.0393\n",
      "Epoch 507/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0401 - val_loss: 0.0425\n",
      "Epoch 508/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0399 - val_loss: 0.0403\n",
      "Epoch 509/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0401 - val_loss: 0.0431\n",
      "Epoch 510/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0399 - val_loss: 0.0406\n",
      "Epoch 511/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0399 - val_loss: 0.0400\n",
      "Epoch 512/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0398 - val_loss: 0.0392\n",
      "Epoch 513/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0399 - val_loss: 0.0392\n",
      "Epoch 514/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0397 - val_loss: 0.0404\n",
      "Epoch 515/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0396 - val_loss: 0.0393\n",
      "Epoch 516/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0398 - val_loss: 0.0393\n",
      "Epoch 517/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0397 - val_loss: 0.0432\n",
      "Epoch 518/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0397 - val_loss: 0.0431\n",
      "Epoch 519/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0395 - val_loss: 0.0387\n",
      "Epoch 520/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0395 - val_loss: 0.0403\n",
      "Epoch 521/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0395 - val_loss: 0.0382\n",
      "Epoch 522/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0394 - val_loss: 0.0388\n",
      "Epoch 523/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0394 - val_loss: 0.0388\n",
      "Epoch 524/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0394 - val_loss: 0.0403\n",
      "Epoch 525/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0395 - val_loss: 0.0393\n",
      "Epoch 526/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0395 - val_loss: 0.0380\n",
      "Epoch 527/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0392 - val_loss: 0.0397\n",
      "Epoch 528/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0391 - val_loss: 0.0416\n",
      "Epoch 529/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0394 - val_loss: 0.0398\n",
      "Epoch 530/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0394 - val_loss: 0.0385\n",
      "Epoch 531/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0392 - val_loss: 0.0400\n",
      "Epoch 532/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0391 - val_loss: 0.0385\n",
      "Epoch 533/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0394 - val_loss: 0.0396\n",
      "Epoch 534/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0392 - val_loss: 0.0401\n",
      "Epoch 535/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0391 - val_loss: 0.0392\n",
      "Epoch 536/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0392 - val_loss: 0.0427\n",
      "Epoch 537/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0392 - val_loss: 0.0388\n",
      "Epoch 538/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0391 - val_loss: 0.0399\n",
      "Epoch 539/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0391 - val_loss: 0.0402\n",
      "Epoch 540/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0391 - val_loss: 0.0401\n",
      "Epoch 541/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0392 - val_loss: 0.0413\n",
      "Epoch 542/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0391 - val_loss: 0.0405\n",
      "Epoch 543/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0388 - val_loss: 0.0405\n",
      "Epoch 544/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0391 - val_loss: 0.0425\n",
      "Epoch 545/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0387 - val_loss: 0.0382\n",
      "Epoch 546/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0390 - val_loss: 0.0380\n",
      "Epoch 547/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0388 - val_loss: 0.0390\n",
      "Epoch 548/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0388 - val_loss: 0.0388\n",
      "Epoch 549/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0389 - val_loss: 0.0391\n",
      "Epoch 550/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0388 - val_loss: 0.0383\n",
      "Epoch 551/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0388 - val_loss: 0.0388\n",
      "Epoch 552/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0389 - val_loss: 0.0405\n",
      "Epoch 553/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0388 - val_loss: 0.0373\n",
      "Epoch 554/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0390 - val_loss: 0.0394\n",
      "Epoch 555/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0387 - val_loss: 0.0380\n",
      "Epoch 556/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0389 - val_loss: 0.0405\n",
      "Epoch 557/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0391\n",
      "Epoch 558/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0389\n",
      "Epoch 559/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0387 - val_loss: 0.0385\n",
      "Epoch 560/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0381\n",
      "Epoch 561/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0378\n",
      "Epoch 562/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0380\n",
      "Epoch 563/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0383 - val_loss: 0.0391\n",
      "Epoch 564/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0385 - val_loss: 0.0370\n",
      "Epoch 565/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0406\n",
      "Epoch 566/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0385 - val_loss: 0.0372\n",
      "Epoch 567/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0385 - val_loss: 0.0413\n",
      "Epoch 568/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0386 - val_loss: 0.0387\n",
      "Epoch 569/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0386 - val_loss: 0.0392\n",
      "Epoch 570/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0384 - val_loss: 0.0384\n",
      "Epoch 571/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0383 - val_loss: 0.0408\n",
      "Epoch 572/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0383 - val_loss: 0.0387\n",
      "Epoch 573/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0384 - val_loss: 0.0386\n",
      "Epoch 574/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0382 - val_loss: 0.0390\n",
      "Epoch 575/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0384 - val_loss: 0.0370\n",
      "Epoch 576/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0384 - val_loss: 0.0386\n",
      "Epoch 577/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0383 - val_loss: 0.0391\n",
      "Epoch 578/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0383 - val_loss: 0.0408\n",
      "Epoch 579/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0384 - val_loss: 0.0408\n",
      "Epoch 580/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0382 - val_loss: 0.0384\n",
      "Epoch 581/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0381 - val_loss: 0.0399\n",
      "Epoch 582/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0382 - val_loss: 0.0406\n",
      "Epoch 583/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0382 - val_loss: 0.0369\n",
      "Epoch 584/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0384 - val_loss: 0.0391\n",
      "Epoch 585/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0381 - val_loss: 0.0384\n",
      "Epoch 586/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0382 - val_loss: 0.0387\n",
      "Epoch 587/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0381 - val_loss: 0.0402\n",
      "Epoch 588/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0380 - val_loss: 0.0405\n",
      "Epoch 589/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0381 - val_loss: 0.0372\n",
      "Epoch 590/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0379 - val_loss: 0.0372\n",
      "Epoch 591/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0379 - val_loss: 0.0381\n",
      "Epoch 592/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0378 - val_loss: 0.0377\n",
      "Epoch 593/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0379 - val_loss: 0.0380\n",
      "Epoch 594/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0377 - val_loss: 0.0399\n",
      "Epoch 595/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0377 - val_loss: 0.0386\n",
      "Epoch 596/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0376 - val_loss: 0.0381\n",
      "Epoch 597/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0377 - val_loss: 0.0363\n",
      "Epoch 598/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0378 - val_loss: 0.0368\n",
      "Epoch 599/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0377 - val_loss: 0.0411\n",
      "Epoch 600/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0377 - val_loss: 0.0367\n",
      "1124/1124 [==============================] - 1s 997us/step\n",
      "\n",
      "Training window:  1\n",
      "Epoch 1/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.1346 - val_loss: 0.1277\n",
      "Epoch 2/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1195 - val_loss: 0.1168\n",
      "Epoch 3/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.1136 - val_loss: 0.1112\n",
      "Epoch 4/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.1090 - val_loss: 0.1095\n",
      "Epoch 5/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1051 - val_loss: 0.1043\n",
      "Epoch 6/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1018 - val_loss: 0.1029\n",
      "Epoch 7/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0994 - val_loss: 0.0985\n",
      "Epoch 8/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0974 - val_loss: 0.0986\n",
      "Epoch 9/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0959 - val_loss: 0.0959\n",
      "Epoch 10/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0945 - val_loss: 0.0967\n",
      "Epoch 11/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0936 - val_loss: 0.0927\n",
      "Epoch 12/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0927 - val_loss: 0.0918\n",
      "Epoch 13/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0919 - val_loss: 0.0930\n",
      "Epoch 14/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0913 - val_loss: 0.0918\n",
      "Epoch 15/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0907 - val_loss: 0.0920\n",
      "Epoch 16/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0900 - val_loss: 0.0895\n",
      "Epoch 17/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0893 - val_loss: 0.0897\n",
      "Epoch 18/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0890 - val_loss: 0.0901\n",
      "Epoch 19/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0884 - val_loss: 0.0880\n",
      "Epoch 20/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0879 - val_loss: 0.0876\n",
      "Epoch 21/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0874 - val_loss: 0.0859\n",
      "Epoch 22/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0869 - val_loss: 0.0878\n",
      "Epoch 23/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0863 - val_loss: 0.0864\n",
      "Epoch 24/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0859 - val_loss: 0.0868\n",
      "Epoch 25/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0856 - val_loss: 0.0879\n",
      "Epoch 26/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0852 - val_loss: 0.0878\n",
      "Epoch 27/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0848 - val_loss: 0.0858\n",
      "Epoch 28/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0845 - val_loss: 0.0851\n",
      "Epoch 29/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0842 - val_loss: 0.0835\n",
      "Epoch 30/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0837 - val_loss: 0.0849\n",
      "Epoch 31/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0833 - val_loss: 0.0846\n",
      "Epoch 32/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0830 - val_loss: 0.0832\n",
      "Epoch 33/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 34/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0822 - val_loss: 0.0820\n",
      "Epoch 35/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0819 - val_loss: 0.0818\n",
      "Epoch 36/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0814 - val_loss: 0.0838\n",
      "Epoch 37/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0809 - val_loss: 0.0814\n",
      "Epoch 38/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0807 - val_loss: 0.0816\n",
      "Epoch 39/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0802 - val_loss: 0.0810\n",
      "Epoch 40/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0800 - val_loss: 0.0819\n",
      "Epoch 41/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0799 - val_loss: 0.0817\n",
      "Epoch 42/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0794 - val_loss: 0.0783\n",
      "Epoch 43/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0790 - val_loss: 0.0826\n",
      "Epoch 44/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0789 - val_loss: 0.0792\n",
      "Epoch 45/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0786 - val_loss: 0.0837\n",
      "Epoch 46/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0785 - val_loss: 0.0783\n",
      "Epoch 47/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0782 - val_loss: 0.0821\n",
      "Epoch 48/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0777 - val_loss: 0.0791\n",
      "Epoch 49/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0776 - val_loss: 0.0784\n",
      "Epoch 50/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0771 - val_loss: 0.0782\n",
      "Epoch 51/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0771 - val_loss: 0.0794\n",
      "Epoch 52/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0767 - val_loss: 0.0777\n",
      "Epoch 53/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0765 - val_loss: 0.0770\n",
      "Epoch 54/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0765 - val_loss: 0.0762\n",
      "Epoch 55/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0763 - val_loss: 0.0764\n",
      "Epoch 56/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0760 - val_loss: 0.0763\n",
      "Epoch 57/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0758 - val_loss: 0.0757\n",
      "Epoch 58/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0754 - val_loss: 0.0750\n",
      "Epoch 59/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0754 - val_loss: 0.0763\n",
      "Epoch 60/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0753 - val_loss: 0.0764\n",
      "Epoch 61/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0752 - val_loss: 0.0771\n",
      "Epoch 62/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0748 - val_loss: 0.0754\n",
      "Epoch 63/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0747 - val_loss: 0.0750\n",
      "Epoch 64/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0746 - val_loss: 0.0737\n",
      "Epoch 65/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0745 - val_loss: 0.0749\n",
      "Epoch 66/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0743 - val_loss: 0.0756\n",
      "Epoch 67/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0741 - val_loss: 0.0738\n",
      "Epoch 68/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0738 - val_loss: 0.0752\n",
      "Epoch 69/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0739 - val_loss: 0.0738\n",
      "Epoch 70/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0736 - val_loss: 0.0745\n",
      "Epoch 71/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0737 - val_loss: 0.0752\n",
      "Epoch 72/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0736 - val_loss: 0.0734\n",
      "Epoch 73/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0733 - val_loss: 0.0736\n",
      "Epoch 74/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0732 - val_loss: 0.0777\n",
      "Epoch 75/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0732 - val_loss: 0.0767\n",
      "Epoch 76/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0729 - val_loss: 0.0763\n",
      "Epoch 77/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0727 - val_loss: 0.0744\n",
      "Epoch 78/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0726 - val_loss: 0.0733\n",
      "Epoch 79/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0726 - val_loss: 0.0737\n",
      "Epoch 80/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0723 - val_loss: 0.0734\n",
      "Epoch 81/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0724 - val_loss: 0.0736\n",
      "Epoch 82/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0722 - val_loss: 0.0731\n",
      "Epoch 83/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0721 - val_loss: 0.0725\n",
      "Epoch 84/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0719 - val_loss: 0.0727\n",
      "Epoch 85/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0716 - val_loss: 0.0730\n",
      "Epoch 86/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0716 - val_loss: 0.0713\n",
      "Epoch 87/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0714 - val_loss: 0.0732\n",
      "Epoch 88/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0712 - val_loss: 0.0733\n",
      "Epoch 89/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0712 - val_loss: 0.0725\n",
      "Epoch 90/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0711 - val_loss: 0.0714\n",
      "Epoch 91/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0709 - val_loss: 0.0708\n",
      "Epoch 92/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0708 - val_loss: 0.0706\n",
      "Epoch 93/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0705 - val_loss: 0.0698\n",
      "Epoch 94/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0705 - val_loss: 0.0714\n",
      "Epoch 95/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0703 - val_loss: 0.0712\n",
      "Epoch 96/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0703 - val_loss: 0.0708\n",
      "Epoch 97/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0700 - val_loss: 0.0718\n",
      "Epoch 98/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0700 - val_loss: 0.0715\n",
      "Epoch 99/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0698 - val_loss: 0.0696\n",
      "Epoch 100/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0694 - val_loss: 0.0699\n",
      "Epoch 101/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0694 - val_loss: 0.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0693 - val_loss: 0.0713\n",
      "Epoch 103/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0691 - val_loss: 0.0725\n",
      "Epoch 104/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0691 - val_loss: 0.0694\n",
      "Epoch 105/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0688 - val_loss: 0.0718\n",
      "Epoch 106/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0686 - val_loss: 0.0695\n",
      "Epoch 107/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0685 - val_loss: 0.0704\n",
      "Epoch 108/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0686 - val_loss: 0.0693\n",
      "Epoch 109/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0682 - val_loss: 0.0724\n",
      "Epoch 110/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0682 - val_loss: 0.0683\n",
      "Epoch 111/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0681 - val_loss: 0.0695\n",
      "Epoch 112/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0678 - val_loss: 0.0678\n",
      "Epoch 113/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0679 - val_loss: 0.0674\n",
      "Epoch 114/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0678 - val_loss: 0.0674\n",
      "Epoch 115/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0676 - val_loss: 0.0679\n",
      "Epoch 116/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0674 - val_loss: 0.0672\n",
      "Epoch 117/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0673 - val_loss: 0.0683\n",
      "Epoch 118/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0673 - val_loss: 0.0690\n",
      "Epoch 119/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0671 - val_loss: 0.0679\n",
      "Epoch 120/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0672 - val_loss: 0.0691\n",
      "Epoch 121/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0669 - val_loss: 0.0681\n",
      "Epoch 122/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0670 - val_loss: 0.0690\n",
      "Epoch 123/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0667 - val_loss: 0.0663\n",
      "Epoch 124/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0666 - val_loss: 0.0701\n",
      "Epoch 125/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0667 - val_loss: 0.0671\n",
      "Epoch 126/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0663 - val_loss: 0.0685\n",
      "Epoch 127/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0663 - val_loss: 0.0682\n",
      "Epoch 128/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0662 - val_loss: 0.0665\n",
      "Epoch 129/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0660 - val_loss: 0.0653\n",
      "Epoch 130/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0660 - val_loss: 0.0652\n",
      "Epoch 131/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0658 - val_loss: 0.0685\n",
      "Epoch 132/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0656 - val_loss: 0.0664\n",
      "Epoch 133/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0683\n",
      "Epoch 134/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0703\n",
      "Epoch 135/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0650 - val_loss: 0.0662\n",
      "Epoch 136/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0647 - val_loss: 0.0644\n",
      "Epoch 137/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0647 - val_loss: 0.0662\n",
      "Epoch 138/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0645 - val_loss: 0.0656\n",
      "Epoch 139/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0643 - val_loss: 0.0670\n",
      "Epoch 140/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0641 - val_loss: 0.0644\n",
      "Epoch 141/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0641 - val_loss: 0.0640\n",
      "Epoch 142/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0638 - val_loss: 0.0674\n",
      "Epoch 143/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0639 - val_loss: 0.0670\n",
      "Epoch 144/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0638 - val_loss: 0.0639\n",
      "Epoch 145/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0634 - val_loss: 0.0652\n",
      "Epoch 146/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0634 - val_loss: 0.0650\n",
      "Epoch 147/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0634 - val_loss: 0.0627\n",
      "Epoch 148/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0632 - val_loss: 0.0650\n",
      "Epoch 149/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0632 - val_loss: 0.0642\n",
      "Epoch 150/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0632 - val_loss: 0.0637\n",
      "Epoch 151/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0632 - val_loss: 0.0651\n",
      "Epoch 152/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0631 - val_loss: 0.0658\n",
      "Epoch 153/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0631 - val_loss: 0.0643\n",
      "Epoch 154/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0627 - val_loss: 0.0653\n",
      "Epoch 155/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0628 - val_loss: 0.0633\n",
      "Epoch 156/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0627 - val_loss: 0.0648\n",
      "Epoch 157/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0641\n",
      "Epoch 158/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0632\n",
      "Epoch 159/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0624 - val_loss: 0.0669\n",
      "Epoch 160/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0622 - val_loss: 0.0653\n",
      "Epoch 161/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0622 - val_loss: 0.0639\n",
      "Epoch 162/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0621 - val_loss: 0.0667\n",
      "Epoch 163/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0621 - val_loss: 0.0642\n",
      "Epoch 164/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0619 - val_loss: 0.0623\n",
      "Epoch 165/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0618 - val_loss: 0.0637\n",
      "Epoch 166/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0618 - val_loss: 0.0620\n",
      "Epoch 167/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0617 - val_loss: 0.0619\n",
      "Epoch 168/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0617 - val_loss: 0.0614\n",
      "Epoch 169/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0616 - val_loss: 0.0615\n",
      "Epoch 170/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0615 - val_loss: 0.0647\n",
      "Epoch 171/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0616 - val_loss: 0.0642\n",
      "Epoch 172/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0609\n",
      "Epoch 173/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0644\n",
      "Epoch 174/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0621\n",
      "Epoch 175/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0611 - val_loss: 0.0629\n",
      "Epoch 176/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0611 - val_loss: 0.0626\n",
      "Epoch 177/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0640\n",
      "Epoch 178/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0628\n",
      "Epoch 179/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0611 - val_loss: 0.0612\n",
      "Epoch 180/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0632\n",
      "Epoch 181/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0611\n",
      "Epoch 182/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0611\n",
      "Epoch 183/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0636\n",
      "Epoch 184/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0609\n",
      "Epoch 185/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0622\n",
      "Epoch 186/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0626\n",
      "Epoch 187/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0613\n",
      "Epoch 188/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0607\n",
      "Epoch 189/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0608\n",
      "Epoch 190/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0601 - val_loss: 0.0621\n",
      "Epoch 191/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0600 - val_loss: 0.0630\n",
      "Epoch 192/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0600 - val_loss: 0.0599\n",
      "Epoch 193/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0620\n",
      "Epoch 194/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0597 - val_loss: 0.0604\n",
      "Epoch 195/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0596 - val_loss: 0.0612\n",
      "Epoch 196/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0596 - val_loss: 0.0608\n",
      "Epoch 197/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0595 - val_loss: 0.0642\n",
      "Epoch 198/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0594 - val_loss: 0.0588\n",
      "Epoch 199/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0593 - val_loss: 0.0622\n",
      "Epoch 200/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0591 - val_loss: 0.0583\n",
      "Epoch 201/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0590 - val_loss: 0.0624\n",
      "Epoch 202/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0589 - val_loss: 0.0604\n",
      "Epoch 203/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0589 - val_loss: 0.0608\n",
      "Epoch 204/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0588 - val_loss: 0.0600\n",
      "Epoch 205/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0587 - val_loss: 0.0590\n",
      "Epoch 206/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0587 - val_loss: 0.0597\n",
      "Epoch 207/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0587 - val_loss: 0.0592\n",
      "Epoch 208/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0586 - val_loss: 0.0591\n",
      "Epoch 209/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0584 - val_loss: 0.0593\n",
      "Epoch 210/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0585 - val_loss: 0.0598\n",
      "Epoch 211/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0584 - val_loss: 0.0592\n",
      "Epoch 212/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0585 - val_loss: 0.0585\n",
      "Epoch 213/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0583 - val_loss: 0.0580\n",
      "Epoch 214/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0581 - val_loss: 0.0577\n",
      "Epoch 215/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0583 - val_loss: 0.0595\n",
      "Epoch 216/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0582 - val_loss: 0.0577\n",
      "Epoch 217/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0580 - val_loss: 0.0619\n",
      "Epoch 218/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0581 - val_loss: 0.0597\n",
      "Epoch 219/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0576 - val_loss: 0.0597\n",
      "Epoch 220/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0577 - val_loss: 0.0577\n",
      "Epoch 221/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0577 - val_loss: 0.0645\n",
      "Epoch 222/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0576 - val_loss: 0.0593\n",
      "Epoch 223/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0575 - val_loss: 0.0584\n",
      "Epoch 224/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0574 - val_loss: 0.0567\n",
      "Epoch 225/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0575 - val_loss: 0.0580\n",
      "Epoch 226/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0572 - val_loss: 0.0602\n",
      "Epoch 227/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0574 - val_loss: 0.0656\n",
      "Epoch 228/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0573 - val_loss: 0.0583\n",
      "Epoch 229/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0572 - val_loss: 0.0579\n",
      "Epoch 230/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0571 - val_loss: 0.0571\n",
      "Epoch 231/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0572 - val_loss: 0.0591\n",
      "Epoch 232/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0570 - val_loss: 0.0581\n",
      "Epoch 233/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0570 - val_loss: 0.0562\n",
      "Epoch 234/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0570 - val_loss: 0.0560\n",
      "Epoch 235/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0569 - val_loss: 0.0578\n",
      "Epoch 236/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0570 - val_loss: 0.0565\n",
      "Epoch 237/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0569 - val_loss: 0.0623\n",
      "Epoch 238/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0569 - val_loss: 0.0606\n",
      "Epoch 239/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0569 - val_loss: 0.0566\n",
      "Epoch 240/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0567 - val_loss: 0.0578\n",
      "Epoch 241/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0566 - val_loss: 0.0573\n",
      "Epoch 242/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0567 - val_loss: 0.0580\n",
      "Epoch 243/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0567 - val_loss: 0.0571\n",
      "Epoch 244/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0567 - val_loss: 0.0584\n",
      "Epoch 245/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0567 - val_loss: 0.0563\n",
      "Epoch 246/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0565 - val_loss: 0.0572\n",
      "Epoch 247/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0565 - val_loss: 0.0606\n",
      "Epoch 248/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0564 - val_loss: 0.0573\n",
      "Epoch 249/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0565 - val_loss: 0.0558\n",
      "Epoch 250/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0563 - val_loss: 0.0572\n",
      "Epoch 251/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0565 - val_loss: 0.0558\n",
      "Epoch 252/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0564 - val_loss: 0.0587\n",
      "Epoch 253/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0562 - val_loss: 0.0605\n",
      "Epoch 254/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0563 - val_loss: 0.0570\n",
      "Epoch 255/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0562 - val_loss: 0.0562\n",
      "Epoch 256/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0563 - val_loss: 0.0582\n",
      "Epoch 257/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0564 - val_loss: 0.0561\n",
      "Epoch 258/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0562 - val_loss: 0.0571\n",
      "Epoch 259/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0562 - val_loss: 0.0558\n",
      "Epoch 260/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0559 - val_loss: 0.0556\n",
      "Epoch 261/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0559 - val_loss: 0.0586\n",
      "Epoch 262/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0559 - val_loss: 0.0554\n",
      "Epoch 263/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0560 - val_loss: 0.0590\n",
      "Epoch 264/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0560 - val_loss: 0.0588\n",
      "Epoch 265/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0559 - val_loss: 0.0561\n",
      "Epoch 266/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0559 - val_loss: 0.0558\n",
      "Epoch 267/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0559 - val_loss: 0.0596\n",
      "Epoch 268/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0557 - val_loss: 0.0563\n",
      "Epoch 269/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0556 - val_loss: 0.0557\n",
      "Epoch 270/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0557 - val_loss: 0.0556\n",
      "Epoch 271/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0556 - val_loss: 0.0567\n",
      "Epoch 272/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0555 - val_loss: 0.0566\n",
      "Epoch 273/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0554 - val_loss: 0.0547\n",
      "Epoch 274/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0557 - val_loss: 0.0574\n",
      "Epoch 275/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0554 - val_loss: 0.0558\n",
      "Epoch 276/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0553 - val_loss: 0.0550\n",
      "Epoch 277/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0555 - val_loss: 0.0593\n",
      "Epoch 278/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0555 - val_loss: 0.0564\n",
      "Epoch 279/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0552 - val_loss: 0.0547\n",
      "Epoch 280/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0554 - val_loss: 0.0565\n",
      "Epoch 281/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0553 - val_loss: 0.0564\n",
      "Epoch 282/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0553 - val_loss: 0.0565\n",
      "Epoch 283/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0551 - val_loss: 0.0562\n",
      "Epoch 284/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0551 - val_loss: 0.0551\n",
      "Epoch 285/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0551 - val_loss: 0.0594\n",
      "Epoch 286/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0550 - val_loss: 0.0555\n",
      "Epoch 287/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0551 - val_loss: 0.0566\n",
      "Epoch 288/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0549 - val_loss: 0.0553\n",
      "Epoch 289/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0549 - val_loss: 0.0562\n",
      "Epoch 290/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0547 - val_loss: 0.0564\n",
      "Epoch 291/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0547 - val_loss: 0.0566\n",
      "Epoch 292/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0546 - val_loss: 0.0568\n",
      "Epoch 293/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0548 - val_loss: 0.0562\n",
      "Epoch 294/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0546 - val_loss: 0.0580\n",
      "Epoch 295/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0546 - val_loss: 0.0572\n",
      "Epoch 296/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0545 - val_loss: 0.0585\n",
      "Epoch 297/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0545 - val_loss: 0.0592\n",
      "Epoch 298/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0545 - val_loss: 0.0548\n",
      "Epoch 299/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0544 - val_loss: 0.0566\n",
      "Epoch 300/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0544 - val_loss: 0.0545\n",
      "Epoch 301/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0544 - val_loss: 0.0546\n",
      "Epoch 302/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0542 - val_loss: 0.0544\n",
      "Epoch 303/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0543 - val_loss: 0.0541\n",
      "Epoch 304/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0541 - val_loss: 0.0543\n",
      "Epoch 305/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0542 - val_loss: 0.0576\n",
      "Epoch 306/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0543 - val_loss: 0.0547\n",
      "Epoch 307/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0540 - val_loss: 0.0547\n",
      "Epoch 308/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0538 - val_loss: 0.0551\n",
      "Epoch 309/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0540 - val_loss: 0.0539\n",
      "Epoch 310/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0542 - val_loss: 0.0547\n",
      "Epoch 311/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0539 - val_loss: 0.0561\n",
      "Epoch 312/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0539 - val_loss: 0.0562\n",
      "Epoch 313/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0539 - val_loss: 0.0560\n",
      "Epoch 314/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0540 - val_loss: 0.0560\n",
      "Epoch 315/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0539 - val_loss: 0.0540\n",
      "Epoch 316/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0536 - val_loss: 0.0564\n",
      "Epoch 317/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0539 - val_loss: 0.0564\n",
      "Epoch 318/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0536 - val_loss: 0.0577\n",
      "Epoch 319/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0536 - val_loss: 0.0553\n",
      "Epoch 320/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0537 - val_loss: 0.0549\n",
      "Epoch 321/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0536 - val_loss: 0.0573\n",
      "Epoch 322/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0536 - val_loss: 0.0548\n",
      "Epoch 323/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0537 - val_loss: 0.0552\n",
      "Epoch 324/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0535 - val_loss: 0.0569\n",
      "Epoch 325/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0534 - val_loss: 0.0554\n",
      "Epoch 326/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0535 - val_loss: 0.0538\n",
      "Epoch 327/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0533 - val_loss: 0.0543\n",
      "Epoch 328/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0535 - val_loss: 0.0554\n",
      "Epoch 329/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0534 - val_loss: 0.0549\n",
      "Epoch 330/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0533 - val_loss: 0.0536\n",
      "Epoch 331/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0532 - val_loss: 0.0535\n",
      "Epoch 332/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0534 - val_loss: 0.0530\n",
      "Epoch 333/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0532 - val_loss: 0.0557\n",
      "Epoch 334/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0532 - val_loss: 0.0551\n",
      "Epoch 335/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0532 - val_loss: 0.0556\n",
      "Epoch 336/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0532 - val_loss: 0.0536\n",
      "Epoch 337/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0532 - val_loss: 0.0544\n",
      "Epoch 338/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0531 - val_loss: 0.0562\n",
      "Epoch 339/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0530 - val_loss: 0.0555\n",
      "Epoch 340/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0531 - val_loss: 0.0541\n",
      "Epoch 341/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0531 - val_loss: 0.0551\n",
      "Epoch 342/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0531 - val_loss: 0.0524\n",
      "Epoch 343/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0528 - val_loss: 0.0545\n",
      "Epoch 344/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0531 - val_loss: 0.0538\n",
      "Epoch 345/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0529 - val_loss: 0.0536\n",
      "Epoch 346/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0530 - val_loss: 0.0543\n",
      "Epoch 347/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0529 - val_loss: 0.0563\n",
      "Epoch 348/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0528 - val_loss: 0.0551\n",
      "Epoch 349/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0527 - val_loss: 0.0548\n",
      "Epoch 350/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0527 - val_loss: 0.0551\n",
      "Epoch 351/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0526 - val_loss: 0.0553\n",
      "Epoch 352/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0526 - val_loss: 0.0590\n",
      "Epoch 353/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0526 - val_loss: 0.0571\n",
      "Epoch 354/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0526 - val_loss: 0.0539\n",
      "Epoch 355/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0526 - val_loss: 0.0541\n",
      "Epoch 356/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0527 - val_loss: 0.0542\n",
      "Epoch 357/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0525 - val_loss: 0.0553\n",
      "Epoch 358/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0527 - val_loss: 0.0549\n",
      "Epoch 359/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0524 - val_loss: 0.0561\n",
      "Epoch 360/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0526 - val_loss: 0.0552\n",
      "Epoch 361/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0524 - val_loss: 0.0546\n",
      "Epoch 362/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0525 - val_loss: 0.0531\n",
      "Epoch 363/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0523 - val_loss: 0.0546\n",
      "Epoch 364/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0524 - val_loss: 0.0525\n",
      "Epoch 365/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0522 - val_loss: 0.0536\n",
      "Epoch 366/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0522 - val_loss: 0.0568\n",
      "Epoch 367/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0520 - val_loss: 0.0528\n",
      "Epoch 368/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0521 - val_loss: 0.0522\n",
      "Epoch 369/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0522 - val_loss: 0.0530\n",
      "Epoch 370/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0520 - val_loss: 0.0536\n",
      "Epoch 371/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0522 - val_loss: 0.0522\n",
      "Epoch 372/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0521 - val_loss: 0.0524\n",
      "Epoch 373/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0522 - val_loss: 0.0546\n",
      "Epoch 374/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0519 - val_loss: 0.0535\n",
      "Epoch 375/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0522 - val_loss: 0.0537\n",
      "Epoch 376/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0518 - val_loss: 0.0543\n",
      "Epoch 377/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0520 - val_loss: 0.0580\n",
      "Epoch 378/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0519 - val_loss: 0.0539\n",
      "Epoch 379/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0519 - val_loss: 0.0524\n",
      "Epoch 380/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0518 - val_loss: 0.0542\n",
      "Epoch 381/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0519 - val_loss: 0.0542\n",
      "Epoch 382/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0518 - val_loss: 0.0544\n",
      "Epoch 383/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0519 - val_loss: 0.0524\n",
      "Epoch 384/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0517 - val_loss: 0.0526\n",
      "Epoch 385/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0518 - val_loss: 0.0524\n",
      "Epoch 386/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0517 - val_loss: 0.0553\n",
      "Epoch 387/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0516 - val_loss: 0.0545\n",
      "Epoch 388/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0516 - val_loss: 0.0527\n",
      "Epoch 389/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0518 - val_loss: 0.0530\n",
      "Epoch 390/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0517 - val_loss: 0.0530\n",
      "Epoch 391/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0518 - val_loss: 0.0524\n",
      "Epoch 392/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0516 - val_loss: 0.0549\n",
      "Epoch 393/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0515 - val_loss: 0.0541\n",
      "Epoch 394/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0516 - val_loss: 0.0529\n",
      "Epoch 395/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0516 - val_loss: 0.0577\n",
      "Epoch 396/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0515 - val_loss: 0.0535\n",
      "Epoch 397/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0515 - val_loss: 0.0522\n",
      "Epoch 398/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0514 - val_loss: 0.0535\n",
      "Epoch 399/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0513 - val_loss: 0.0515\n",
      "Epoch 400/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0515 - val_loss: 0.0543\n",
      "Epoch 401/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0515 - val_loss: 0.0523\n",
      "Epoch 402/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0515 - val_loss: 0.0525\n",
      "Epoch 403/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0515 - val_loss: 0.0523\n",
      "Epoch 404/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0513 - val_loss: 0.0523\n",
      "Epoch 405/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0514 - val_loss: 0.0527\n",
      "Epoch 406/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0516 - val_loss: 0.0545\n",
      "Epoch 407/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0513 - val_loss: 0.0548\n",
      "Epoch 408/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0513 - val_loss: 0.0567\n",
      "Epoch 409/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0515 - val_loss: 0.0516\n",
      "Epoch 410/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0512 - val_loss: 0.0546\n",
      "Epoch 411/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0513 - val_loss: 0.0533\n",
      "Epoch 412/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0512 - val_loss: 0.0548\n",
      "Epoch 413/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0514 - val_loss: 0.0531\n",
      "Epoch 414/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0513 - val_loss: 0.0524\n",
      "Epoch 415/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0512 - val_loss: 0.0527\n",
      "Epoch 416/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0511 - val_loss: 0.0525\n",
      "Epoch 417/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0511 - val_loss: 0.0524\n",
      "Epoch 418/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0512 - val_loss: 0.0539\n",
      "Epoch 419/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0511 - val_loss: 0.0524\n",
      "Epoch 420/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0512 - val_loss: 0.0528\n",
      "Epoch 421/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0510 - val_loss: 0.0564\n",
      "Epoch 422/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0510 - val_loss: 0.0508\n",
      "Epoch 423/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0511 - val_loss: 0.0517\n",
      "Epoch 424/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0510 - val_loss: 0.0524\n",
      "Epoch 425/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0509 - val_loss: 0.0546\n",
      "Epoch 426/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0511 - val_loss: 0.0507\n",
      "Epoch 427/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0509 - val_loss: 0.0518\n",
      "Epoch 428/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0508 - val_loss: 0.0510\n",
      "Epoch 429/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0509 - val_loss: 0.0529\n",
      "Epoch 430/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0508 - val_loss: 0.0539\n",
      "Epoch 431/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0508 - val_loss: 0.0570\n",
      "Epoch 432/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0530\n",
      "Epoch 433/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0517\n",
      "Epoch 434/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0508 - val_loss: 0.0526\n",
      "Epoch 435/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0520\n",
      "Epoch 436/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0506 - val_loss: 0.0511\n",
      "Epoch 437/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0543\n",
      "Epoch 438/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0541\n",
      "Epoch 439/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0526\n",
      "Epoch 440/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0507 - val_loss: 0.0516\n",
      "Epoch 441/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0506 - val_loss: 0.0506\n",
      "Epoch 442/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0508 - val_loss: 0.0511\n",
      "Epoch 443/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0506 - val_loss: 0.0533\n",
      "Epoch 444/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0506 - val_loss: 0.0507\n",
      "Epoch 445/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0505 - val_loss: 0.0555\n",
      "Epoch 446/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0505 - val_loss: 0.0514\n",
      "Epoch 447/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0505 - val_loss: 0.0520\n",
      "Epoch 448/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0505 - val_loss: 0.0523\n",
      "Epoch 449/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0504 - val_loss: 0.0519\n",
      "Epoch 450/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0503 - val_loss: 0.0512\n",
      "Epoch 451/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0506 - val_loss: 0.0529\n",
      "Epoch 452/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0503 - val_loss: 0.0526\n",
      "Epoch 453/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0504 - val_loss: 0.0531\n",
      "Epoch 454/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0504 - val_loss: 0.0514\n",
      "Epoch 455/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0504 - val_loss: 0.0530\n",
      "Epoch 456/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0503 - val_loss: 0.0518\n",
      "Epoch 457/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0504 - val_loss: 0.0512\n",
      "Epoch 458/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0503 - val_loss: 0.0527\n",
      "Epoch 459/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0503 - val_loss: 0.0509\n",
      "Epoch 460/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0501 - val_loss: 0.0511\n",
      "Epoch 461/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0502 - val_loss: 0.0507\n",
      "Epoch 462/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0504 - val_loss: 0.0515\n",
      "Epoch 463/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0501 - val_loss: 0.0518\n",
      "Epoch 464/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0502 - val_loss: 0.0519\n",
      "Epoch 465/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0500 - val_loss: 0.0522\n",
      "Epoch 466/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0500 - val_loss: 0.0507\n",
      "Epoch 467/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0499 - val_loss: 0.0513\n",
      "Epoch 468/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0499 - val_loss: 0.0518\n",
      "Epoch 469/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0501 - val_loss: 0.0507\n",
      "Epoch 470/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0500 - val_loss: 0.0512\n",
      "Epoch 471/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0498 - val_loss: 0.0509\n",
      "Epoch 472/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0498 - val_loss: 0.0565\n",
      "Epoch 473/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0499 - val_loss: 0.0533\n",
      "Epoch 474/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0499 - val_loss: 0.0542\n",
      "Epoch 475/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0500 - val_loss: 0.0521\n",
      "Epoch 476/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0499 - val_loss: 0.0505\n",
      "Epoch 477/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0504\n",
      "Epoch 478/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0497 - val_loss: 0.0518\n",
      "Epoch 479/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0499 - val_loss: 0.0515\n",
      "Epoch 480/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0497 - val_loss: 0.0542\n",
      "Epoch 481/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0500\n",
      "Epoch 482/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0506\n",
      "Epoch 483/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0516\n",
      "Epoch 484/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0496\n",
      "Epoch 485/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0501\n",
      "Epoch 486/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0495 - val_loss: 0.0508\n",
      "Epoch 487/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0521\n",
      "Epoch 488/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0509\n",
      "Epoch 489/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0500\n",
      "Epoch 490/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0546\n",
      "Epoch 491/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0494 - val_loss: 0.0501\n",
      "Epoch 492/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0500\n",
      "Epoch 493/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0495 - val_loss: 0.0503\n",
      "Epoch 494/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0496 - val_loss: 0.0523\n",
      "Epoch 495/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0496\n",
      "Epoch 496/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0493 - val_loss: 0.0494\n",
      "Epoch 497/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0522\n",
      "Epoch 498/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0496\n",
      "Epoch 499/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0495 - val_loss: 0.0553\n",
      "Epoch 500/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0491 - val_loss: 0.0513\n",
      "Epoch 501/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0491\n",
      "Epoch 502/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0493\n",
      "Epoch 503/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0492 - val_loss: 0.0497\n",
      "Epoch 504/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0502\n",
      "Epoch 505/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0520\n",
      "Epoch 506/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0494 - val_loss: 0.0490\n",
      "Epoch 507/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0507\n",
      "Epoch 508/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0500\n",
      "Epoch 509/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0524\n",
      "Epoch 510/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0518\n",
      "Epoch 511/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0514\n",
      "Epoch 512/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0498\n",
      "Epoch 513/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0499\n",
      "Epoch 514/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0492 - val_loss: 0.0520\n",
      "Epoch 515/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0500\n",
      "Epoch 516/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0491 - val_loss: 0.0502\n",
      "Epoch 517/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0489 - val_loss: 0.0503\n",
      "Epoch 518/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0493\n",
      "Epoch 519/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0497\n",
      "Epoch 520/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0491\n",
      "Epoch 521/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0513\n",
      "Epoch 522/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0488 - val_loss: 0.0502\n",
      "Epoch 523/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0489 - val_loss: 0.0495\n",
      "Epoch 524/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0489 - val_loss: 0.0508\n",
      "Epoch 525/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0488 - val_loss: 0.0499\n",
      "Epoch 526/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0491\n",
      "Epoch 527/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0489 - val_loss: 0.0500\n",
      "Epoch 528/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0488 - val_loss: 0.0510\n",
      "Epoch 529/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0490 - val_loss: 0.0495\n",
      "Epoch 530/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0488 - val_loss: 0.0516\n",
      "Epoch 531/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0495\n",
      "Epoch 532/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0489 - val_loss: 0.0496\n",
      "Epoch 533/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0499\n",
      "Epoch 534/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0489\n",
      "Epoch 535/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0489 - val_loss: 0.0513\n",
      "Epoch 536/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0488 - val_loss: 0.0490\n",
      "Epoch 537/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0487\n",
      "Epoch 538/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0494\n",
      "Epoch 539/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0488 - val_loss: 0.0488\n",
      "Epoch 540/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0497\n",
      "Epoch 541/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0487 - val_loss: 0.0484\n",
      "Epoch 542/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0510\n",
      "Epoch 543/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0493\n",
      "Epoch 544/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0502\n",
      "Epoch 545/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0524\n",
      "Epoch 546/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0486\n",
      "Epoch 547/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0511\n",
      "Epoch 548/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0535\n",
      "Epoch 549/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0485 - val_loss: 0.0501\n",
      "Epoch 550/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0487 - val_loss: 0.0486\n",
      "Epoch 551/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0505\n",
      "Epoch 552/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0514\n",
      "Epoch 553/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0498\n",
      "Epoch 554/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0486 - val_loss: 0.0503\n",
      "Epoch 555/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0485 - val_loss: 0.0501\n",
      "Epoch 556/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0492\n",
      "Epoch 557/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0485 - val_loss: 0.0517\n",
      "Epoch 558/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0496\n",
      "Epoch 559/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0514\n",
      "Epoch 560/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0494\n",
      "Epoch 561/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0498\n",
      "Epoch 562/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0486 - val_loss: 0.0497\n",
      "Epoch 563/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0488\n",
      "Epoch 564/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0503\n",
      "Epoch 565/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0506\n",
      "Epoch 566/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0507\n",
      "Epoch 567/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0494\n",
      "Epoch 568/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0485 - val_loss: 0.0496\n",
      "Epoch 569/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0503\n",
      "Epoch 570/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0483\n",
      "Epoch 571/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0482\n",
      "Epoch 572/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0484\n",
      "Epoch 573/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0510\n",
      "Epoch 574/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0485\n",
      "Epoch 575/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0483\n",
      "Epoch 576/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0482\n",
      "Epoch 577/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0486\n",
      "Epoch 578/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0484 - val_loss: 0.0504\n",
      "Epoch 579/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0484\n",
      "Epoch 580/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0510\n",
      "Epoch 581/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0494\n",
      "Epoch 582/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0499\n",
      "Epoch 583/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0483 - val_loss: 0.0494\n",
      "Epoch 584/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0477\n",
      "Epoch 585/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0498\n",
      "Epoch 586/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0480 - val_loss: 0.0496\n",
      "Epoch 587/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0489\n",
      "Epoch 588/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0495\n",
      "Epoch 589/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0503\n",
      "Epoch 590/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0482\n",
      "Epoch 591/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0504\n",
      "Epoch 592/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0480 - val_loss: 0.0493\n",
      "Epoch 593/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0479 - val_loss: 0.0506\n",
      "Epoch 594/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0480 - val_loss: 0.0505\n",
      "Epoch 595/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0480 - val_loss: 0.0484\n",
      "Epoch 596/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0482 - val_loss: 0.0490\n",
      "Epoch 597/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0491\n",
      "Epoch 598/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0479 - val_loss: 0.0483\n",
      "Epoch 599/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0480 - val_loss: 0.0475\n",
      "Epoch 600/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0481 - val_loss: 0.0495\n",
      "1124/1124 [==============================] - 1s 1ms/step\n",
      "\n",
      "Training window:  2\n",
      "Epoch 1/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.1430 - val_loss: 0.1355\n",
      "Epoch 2/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1320 - val_loss: 0.1325\n",
      "Epoch 3/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1289 - val_loss: 0.1280\n",
      "Epoch 4/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1266 - val_loss: 0.1267\n",
      "Epoch 5/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1248 - val_loss: 0.1261\n",
      "Epoch 6/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1232 - val_loss: 0.1233\n",
      "Epoch 7/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1216 - val_loss: 0.1229\n",
      "Epoch 8/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1201 - val_loss: 0.1193\n",
      "Epoch 9/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1185 - val_loss: 0.1184\n",
      "Epoch 10/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1171 - val_loss: 0.1169\n",
      "Epoch 11/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1155 - val_loss: 0.1153\n",
      "Epoch 12/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1141 - val_loss: 0.1137\n",
      "Epoch 13/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1126 - val_loss: 0.1134\n",
      "Epoch 14/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1114 - val_loss: 0.1115\n",
      "Epoch 15/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1101 - val_loss: 0.1111\n",
      "Epoch 16/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.1091 - val_loss: 0.1101\n",
      "Epoch 17/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1081 - val_loss: 0.1077\n",
      "Epoch 18/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1071 - val_loss: 0.1081\n",
      "Epoch 19/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1062 - val_loss: 0.1053\n",
      "Epoch 20/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1051 - val_loss: 0.1044\n",
      "Epoch 21/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1041 - val_loss: 0.1049\n",
      "Epoch 22/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1033 - val_loss: 0.1041\n",
      "Epoch 23/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1025 - val_loss: 0.1018\n",
      "Epoch 24/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1018 - val_loss: 0.1021\n",
      "Epoch 25/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1010 - val_loss: 0.1064\n",
      "Epoch 26/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.1002 - val_loss: 0.1003\n",
      "Epoch 27/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0999 - val_loss: 0.0990\n",
      "Epoch 28/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0993 - val_loss: 0.1017\n",
      "Epoch 29/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0987 - val_loss: 0.1045\n",
      "Epoch 30/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0982 - val_loss: 0.0985\n",
      "Epoch 31/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0980 - val_loss: 0.1007\n",
      "Epoch 32/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0974 - val_loss: 0.1005\n",
      "Epoch 33/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0971 - val_loss: 0.0992\n",
      "Epoch 34/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0964 - val_loss: 0.0958\n",
      "Epoch 35/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0959 - val_loss: 0.0966\n",
      "Epoch 36/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0956 - val_loss: 0.0961\n",
      "Epoch 37/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0954 - val_loss: 0.0949\n",
      "Epoch 38/600\n",
      "3035/3035 [==============================] - 4s 1ms/step - loss: 0.0947 - val_loss: 0.0964\n",
      "Epoch 39/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0946 - val_loss: 0.0944\n",
      "Epoch 40/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0942 - val_loss: 0.0954\n",
      "Epoch 41/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0939 - val_loss: 0.0938\n",
      "Epoch 42/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0937 - val_loss: 0.0935\n",
      "Epoch 43/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0933 - val_loss: 0.0931\n",
      "Epoch 44/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0930 - val_loss: 0.0930\n",
      "Epoch 45/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0925 - val_loss: 0.0922\n",
      "Epoch 46/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0922 - val_loss: 0.0919\n",
      "Epoch 47/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0918 - val_loss: 0.0924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0916 - val_loss: 0.0911\n",
      "Epoch 49/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0912 - val_loss: 0.0918\n",
      "Epoch 50/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0909 - val_loss: 0.0903\n",
      "Epoch 51/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0908 - val_loss: 0.0933\n",
      "Epoch 52/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0903 - val_loss: 0.0918\n",
      "Epoch 53/600\n",
      "3035/3035 [==============================] - 14s 4ms/step - loss: 0.0902 - val_loss: 0.0914\n",
      "Epoch 54/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0899 - val_loss: 0.0898\n",
      "Epoch 55/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0897 - val_loss: 0.0908\n",
      "Epoch 56/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0895 - val_loss: 0.0906\n",
      "Epoch 57/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0893 - val_loss: 0.0911\n",
      "Epoch 58/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0893 - val_loss: 0.0898\n",
      "Epoch 59/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0891 - val_loss: 0.0893\n",
      "Epoch 60/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0888 - val_loss: 0.0912\n",
      "Epoch 61/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0889 - val_loss: 0.0892\n",
      "Epoch 62/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0885 - val_loss: 0.0902\n",
      "Epoch 63/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0883 - val_loss: 0.0888\n",
      "Epoch 64/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0882 - val_loss: 0.0883\n",
      "Epoch 65/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0882 - val_loss: 0.0872\n",
      "Epoch 66/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0879 - val_loss: 0.0885\n",
      "Epoch 67/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0878 - val_loss: 0.0908\n",
      "Epoch 68/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0875 - val_loss: 0.0889\n",
      "Epoch 69/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0875 - val_loss: 0.0893\n",
      "Epoch 70/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0874 - val_loss: 0.0882\n",
      "Epoch 71/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0874 - val_loss: 0.0902\n",
      "Epoch 72/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0872 - val_loss: 0.0908\n",
      "Epoch 73/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0873 - val_loss: 0.0878\n",
      "Epoch 74/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0870 - val_loss: 0.0859\n",
      "Epoch 75/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0871 - val_loss: 0.0903\n",
      "Epoch 76/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0866 - val_loss: 0.0889\n",
      "Epoch 77/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0869 - val_loss: 0.0888\n",
      "Epoch 78/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0866 - val_loss: 0.0874\n",
      "Epoch 79/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0866 - val_loss: 0.0877\n",
      "Epoch 80/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0864 - val_loss: 0.0876\n",
      "Epoch 81/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0863 - val_loss: 0.0867\n",
      "Epoch 82/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0865 - val_loss: 0.0876\n",
      "Epoch 83/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0861 - val_loss: 0.0880\n",
      "Epoch 84/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0862 - val_loss: 0.0878\n",
      "Epoch 85/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0861 - val_loss: 0.0873\n",
      "Epoch 86/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0861 - val_loss: 0.0856\n",
      "Epoch 87/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0860 - val_loss: 0.0890\n",
      "Epoch 88/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0861 - val_loss: 0.0878\n",
      "Epoch 89/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0860 - val_loss: 0.0862\n",
      "Epoch 90/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0856 - val_loss: 0.0870\n",
      "Epoch 91/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0855 - val_loss: 0.0883\n",
      "Epoch 92/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0852 - val_loss: 0.0854\n",
      "Epoch 93/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0855 - val_loss: 0.0877\n",
      "Epoch 94/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0854 - val_loss: 0.0863\n",
      "Epoch 95/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0853 - val_loss: 0.0858\n",
      "Epoch 96/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0849 - val_loss: 0.0859\n",
      "Epoch 97/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0850 - val_loss: 0.0872\n",
      "Epoch 98/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0850 - val_loss: 0.0859\n",
      "Epoch 99/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0849 - val_loss: 0.0848\n",
      "Epoch 100/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0847 - val_loss: 0.0859\n",
      "Epoch 101/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0846 - val_loss: 0.0911\n",
      "Epoch 102/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0847 - val_loss: 0.0856\n",
      "Epoch 103/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0847 - val_loss: 0.0855\n",
      "Epoch 104/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0842 - val_loss: 0.0865\n",
      "Epoch 105/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0840 - val_loss: 0.0879\n",
      "Epoch 106/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0842 - val_loss: 0.0856\n",
      "Epoch 107/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0841 - val_loss: 0.0840\n",
      "Epoch 108/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0838 - val_loss: 0.0852\n",
      "Epoch 109/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0836 - val_loss: 0.0855\n",
      "Epoch 110/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0838 - val_loss: 0.0838\n",
      "Epoch 111/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0834 - val_loss: 0.0835\n",
      "Epoch 112/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0834 - val_loss: 0.0843\n",
      "Epoch 113/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0834 - val_loss: 0.0835\n",
      "Epoch 114/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 115/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0829 - val_loss: 0.0839\n",
      "Epoch 116/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0832 - val_loss: 0.0838\n",
      "Epoch 117/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0830 - val_loss: 0.0825\n",
      "Epoch 118/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0830 - val_loss: 0.0846\n",
      "Epoch 119/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0828 - val_loss: 0.0829\n",
      "Epoch 120/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0827 - val_loss: 0.0836\n",
      "Epoch 121/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0826 - val_loss: 0.0835\n",
      "Epoch 122/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0824 - val_loss: 0.0831\n",
      "Epoch 123/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0826 - val_loss: 0.0811\n",
      "Epoch 124/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0825 - val_loss: 0.0841\n",
      "Epoch 125/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0824 - val_loss: 0.0838\n",
      "Epoch 126/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0822 - val_loss: 0.0891\n",
      "Epoch 127/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0822 - val_loss: 0.0828\n",
      "Epoch 128/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0821 - val_loss: 0.0851\n",
      "Epoch 129/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0821 - val_loss: 0.0827\n",
      "Epoch 130/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0821 - val_loss: 0.0825\n",
      "Epoch 131/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0821 - val_loss: 0.0849\n",
      "Epoch 132/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0820 - val_loss: 0.0854\n",
      "Epoch 133/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0819 - val_loss: 0.0821\n",
      "Epoch 134/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0819 - val_loss: 0.0826\n",
      "Epoch 135/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0818 - val_loss: 0.0832\n",
      "Epoch 136/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0818 - val_loss: 0.0831\n",
      "Epoch 137/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0816 - val_loss: 0.0829\n",
      "Epoch 138/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0817 - val_loss: 0.0812\n",
      "Epoch 139/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0815 - val_loss: 0.0821\n",
      "Epoch 140/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0815 - val_loss: 0.0815\n",
      "Epoch 141/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0815 - val_loss: 0.0829\n",
      "Epoch 142/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0813 - val_loss: 0.0805\n",
      "Epoch 143/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0813 - val_loss: 0.0820\n",
      "Epoch 144/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0814 - val_loss: 0.0856\n",
      "Epoch 145/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0815 - val_loss: 0.0831\n",
      "Epoch 146/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0810 - val_loss: 0.0814\n",
      "Epoch 147/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0810 - val_loss: 0.0827\n",
      "Epoch 148/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0811 - val_loss: 0.0852\n",
      "Epoch 149/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0810 - val_loss: 0.0805\n",
      "Epoch 150/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0811 - val_loss: 0.0820\n",
      "Epoch 151/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0810 - val_loss: 0.0809\n",
      "Epoch 152/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0807 - val_loss: 0.0814\n",
      "Epoch 153/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0809 - val_loss: 0.0807\n",
      "Epoch 154/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0807 - val_loss: 0.0819\n",
      "Epoch 155/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0806 - val_loss: 0.0813\n",
      "Epoch 156/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0806 - val_loss: 0.0797\n",
      "Epoch 157/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0803 - val_loss: 0.0806\n",
      "Epoch 158/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0802 - val_loss: 0.0811\n",
      "Epoch 159/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0804 - val_loss: 0.0855\n",
      "Epoch 160/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0804 - val_loss: 0.0823\n",
      "Epoch 161/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0803 - val_loss: 0.0842\n",
      "Epoch 162/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0805 - val_loss: 0.0819\n",
      "Epoch 163/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0803 - val_loss: 0.0815\n",
      "Epoch 164/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0800 - val_loss: 0.0836\n",
      "Epoch 165/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0799 - val_loss: 0.0816\n",
      "Epoch 166/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0801 - val_loss: 0.0797\n",
      "Epoch 167/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0798 - val_loss: 0.0802\n",
      "Epoch 168/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0798 - val_loss: 0.0812\n",
      "Epoch 169/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0800 - val_loss: 0.0809\n",
      "Epoch 170/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0799 - val_loss: 0.0849\n",
      "Epoch 171/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0796 - val_loss: 0.0816\n",
      "Epoch 172/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0797 - val_loss: 0.0852\n",
      "Epoch 173/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0796 - val_loss: 0.0797\n",
      "Epoch 174/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0795 - val_loss: 0.0804\n",
      "Epoch 175/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0795 - val_loss: 0.0803\n",
      "Epoch 176/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0794 - val_loss: 0.0814\n",
      "Epoch 177/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0796 - val_loss: 0.0805\n",
      "Epoch 178/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0795 - val_loss: 0.0821\n",
      "Epoch 179/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0794 - val_loss: 0.0795\n",
      "Epoch 180/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0796 - val_loss: 0.0826\n",
      "Epoch 181/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0792 - val_loss: 0.0821\n",
      "Epoch 182/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0796 - val_loss: 0.0827\n",
      "Epoch 183/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0793 - val_loss: 0.0818\n",
      "Epoch 184/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0791 - val_loss: 0.0821\n",
      "Epoch 185/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0791 - val_loss: 0.0809\n",
      "Epoch 186/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0792 - val_loss: 0.0813\n",
      "Epoch 187/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0792 - val_loss: 0.0863\n",
      "Epoch 188/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0793 - val_loss: 0.0818\n",
      "Epoch 189/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0790 - val_loss: 0.0821\n",
      "Epoch 190/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0791 - val_loss: 0.0791\n",
      "Epoch 191/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0789 - val_loss: 0.0798\n",
      "Epoch 192/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0788 - val_loss: 0.0797\n",
      "Epoch 193/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0790 - val_loss: 0.0800\n",
      "Epoch 194/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0790 - val_loss: 0.0799\n",
      "Epoch 195/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0788 - val_loss: 0.0844\n",
      "Epoch 196/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0786 - val_loss: 0.0795\n",
      "Epoch 197/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0789 - val_loss: 0.0799\n",
      "Epoch 198/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0785 - val_loss: 0.0825\n",
      "Epoch 199/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0786 - val_loss: 0.0792\n",
      "Epoch 200/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0782 - val_loss: 0.0864\n",
      "Epoch 201/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0787 - val_loss: 0.0788\n",
      "Epoch 202/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0786 - val_loss: 0.0810\n",
      "Epoch 203/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0783 - val_loss: 0.0806\n",
      "Epoch 204/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0785 - val_loss: 0.0820\n",
      "Epoch 205/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0784 - val_loss: 0.0791\n",
      "Epoch 206/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0783 - val_loss: 0.0782\n",
      "Epoch 207/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0785 - val_loss: 0.0841\n",
      "Epoch 208/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0784 - val_loss: 0.0789\n",
      "Epoch 209/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0783 - val_loss: 0.0793\n",
      "Epoch 210/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0782 - val_loss: 0.0792\n",
      "Epoch 211/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0782 - val_loss: 0.0788\n",
      "Epoch 212/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0780 - val_loss: 0.0838\n",
      "Epoch 213/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0782 - val_loss: 0.0812\n",
      "Epoch 214/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0782 - val_loss: 0.0793\n",
      "Epoch 215/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0782 - val_loss: 0.0788\n",
      "Epoch 216/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0781 - val_loss: 0.0802\n",
      "Epoch 217/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0781 - val_loss: 0.0801\n",
      "Epoch 218/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0782 - val_loss: 0.0779\n",
      "Epoch 219/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0778 - val_loss: 0.0773\n",
      "Epoch 220/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0779 - val_loss: 0.0798\n",
      "Epoch 221/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0779 - val_loss: 0.0811\n",
      "Epoch 222/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0777 - val_loss: 0.0803\n",
      "Epoch 223/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0778 - val_loss: 0.0799\n",
      "Epoch 224/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0777 - val_loss: 0.0795\n",
      "Epoch 225/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0780 - val_loss: 0.0795\n",
      "Epoch 226/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0777 - val_loss: 0.0783\n",
      "Epoch 227/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0778 - val_loss: 0.0804\n",
      "Epoch 228/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0777 - val_loss: 0.0786\n",
      "Epoch 229/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0778 - val_loss: 0.0817\n",
      "Epoch 230/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0776 - val_loss: 0.0780\n",
      "Epoch 231/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0776 - val_loss: 0.0766\n",
      "Epoch 232/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0775 - val_loss: 0.0823\n",
      "Epoch 233/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0776 - val_loss: 0.0779\n",
      "Epoch 234/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0778 - val_loss: 0.0800\n",
      "Epoch 235/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0774 - val_loss: 0.0795\n",
      "Epoch 236/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0776 - val_loss: 0.0801\n",
      "Epoch 237/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0775 - val_loss: 0.0830\n",
      "Epoch 238/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0775 - val_loss: 0.0778\n",
      "Epoch 239/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0775 - val_loss: 0.0785\n",
      "Epoch 240/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0772 - val_loss: 0.0779\n",
      "Epoch 241/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0774 - val_loss: 0.0783\n",
      "Epoch 242/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0774 - val_loss: 0.0801\n",
      "Epoch 243/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0772 - val_loss: 0.0792\n",
      "Epoch 244/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0771 - val_loss: 0.0791\n",
      "Epoch 245/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0772 - val_loss: 0.0772\n",
      "Epoch 246/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0773 - val_loss: 0.0777\n",
      "Epoch 247/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0772 - val_loss: 0.0778\n",
      "Epoch 248/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0771 - val_loss: 0.0825\n",
      "Epoch 249/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0773 - val_loss: 0.0790\n",
      "Epoch 250/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0770 - val_loss: 0.0777\n",
      "Epoch 251/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0770 - val_loss: 0.0776\n",
      "Epoch 252/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0769 - val_loss: 0.0765\n",
      "Epoch 253/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0770 - val_loss: 0.0792\n",
      "Epoch 254/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0769 - val_loss: 0.0800\n",
      "Epoch 255/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0772 - val_loss: 0.0777\n",
      "Epoch 256/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0771 - val_loss: 0.0802\n",
      "Epoch 257/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0769 - val_loss: 0.0795\n",
      "Epoch 258/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0768 - val_loss: 0.0775\n",
      "Epoch 259/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0766 - val_loss: 0.0763\n",
      "Epoch 260/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0768 - val_loss: 0.0774\n",
      "Epoch 261/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0771 - val_loss: 0.0781\n",
      "Epoch 262/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0770 - val_loss: 0.0774\n",
      "Epoch 263/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0769 - val_loss: 0.0785\n",
      "Epoch 264/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0768 - val_loss: 0.0799\n",
      "Epoch 265/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0768 - val_loss: 0.0795\n",
      "Epoch 266/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0768 - val_loss: 0.0769\n",
      "Epoch 267/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0768 - val_loss: 0.0790\n",
      "Epoch 268/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0768 - val_loss: 0.0791\n",
      "Epoch 269/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0794\n",
      "Epoch 270/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0790\n",
      "Epoch 271/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0771\n",
      "Epoch 272/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0765 - val_loss: 0.0775\n",
      "Epoch 273/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0770 - val_loss: 0.0779\n",
      "Epoch 274/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0768 - val_loss: 0.0778\n",
      "Epoch 275/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0769 - val_loss: 0.0793\n",
      "Epoch 276/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 277/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0766 - val_loss: 0.0787\n",
      "Epoch 278/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0777\n",
      "Epoch 279/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0768 - val_loss: 0.0784\n",
      "Epoch 280/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0766 - val_loss: 0.0786\n",
      "Epoch 281/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0770\n",
      "Epoch 282/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0786\n",
      "Epoch 283/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0767 - val_loss: 0.0773\n",
      "Epoch 284/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0766 - val_loss: 0.0785\n",
      "Epoch 285/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0806\n",
      "Epoch 286/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0793\n",
      "Epoch 287/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0766 - val_loss: 0.0788\n",
      "Epoch 288/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0773\n",
      "Epoch 289/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0784\n",
      "Epoch 290/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0782\n",
      "Epoch 291/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0774\n",
      "Epoch 292/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0765 - val_loss: 0.0778\n",
      "Epoch 293/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0795\n",
      "Epoch 294/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0787\n",
      "Epoch 295/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0779\n",
      "Epoch 296/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0812\n",
      "Epoch 297/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0763 - val_loss: 0.0758\n",
      "Epoch 298/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0765 - val_loss: 0.0776\n",
      "Epoch 299/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0761 - val_loss: 0.0778\n",
      "Epoch 300/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0771\n",
      "Epoch 301/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0765 - val_loss: 0.0776\n",
      "Epoch 302/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0763 - val_loss: 0.0768\n",
      "Epoch 303/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0764 - val_loss: 0.0781\n",
      "Epoch 304/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0782\n",
      "Epoch 305/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0776\n",
      "Epoch 306/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0798\n",
      "Epoch 307/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0779\n",
      "Epoch 308/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0761 - val_loss: 0.0794\n",
      "Epoch 309/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0779\n",
      "Epoch 310/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0759 - val_loss: 0.0767\n",
      "Epoch 311/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0763 - val_loss: 0.0789\n",
      "Epoch 312/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0792\n",
      "Epoch 313/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0761\n",
      "Epoch 314/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0759\n",
      "Epoch 315/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0775\n",
      "Epoch 316/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0761 - val_loss: 0.0782\n",
      "Epoch 317/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0761 - val_loss: 0.0815\n",
      "Epoch 318/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0778\n",
      "Epoch 319/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0761 - val_loss: 0.0776\n",
      "Epoch 320/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0762 - val_loss: 0.0815\n",
      "Epoch 321/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0760 - val_loss: 0.0776\n",
      "Epoch 322/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0762 - val_loss: 0.0775\n",
      "Epoch 323/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0761 - val_loss: 0.0807\n",
      "Epoch 324/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0761 - val_loss: 0.0782\n",
      "Epoch 325/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0760 - val_loss: 0.0773\n",
      "Epoch 326/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0762 - val_loss: 0.0786\n",
      "Epoch 327/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0759 - val_loss: 0.0785\n",
      "Epoch 328/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0761 - val_loss: 0.0786\n",
      "Epoch 329/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0760 - val_loss: 0.0768\n",
      "Epoch 330/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0759 - val_loss: 0.0768\n",
      "Epoch 331/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0761 - val_loss: 0.0764\n",
      "Epoch 332/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0762 - val_loss: 0.0760\n",
      "Epoch 333/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0760 - val_loss: 0.0779\n",
      "Epoch 334/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0761 - val_loss: 0.0760\n",
      "Epoch 335/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0782 - val_loss: 0.0838\n",
      "Epoch 336/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0760 - val_loss: 0.0765\n",
      "Epoch 337/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0770\n",
      "Epoch 338/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0758\n",
      "Epoch 339/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0763 - val_loss: 0.0790\n",
      "Epoch 340/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0760 - val_loss: 0.0773\n",
      "Epoch 341/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0761\n",
      "Epoch 342/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0760 - val_loss: 0.0787\n",
      "Epoch 343/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0759 - val_loss: 0.0874\n",
      "Epoch 344/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0771\n",
      "Epoch 345/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0762\n",
      "Epoch 346/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0759 - val_loss: 0.0782\n",
      "Epoch 347/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0759 - val_loss: 0.0768\n",
      "Epoch 348/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0787\n",
      "Epoch 349/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0759 - val_loss: 0.0775\n",
      "Epoch 350/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0766\n",
      "Epoch 351/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0758\n",
      "Epoch 352/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0794\n",
      "Epoch 353/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0794\n",
      "Epoch 354/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0768\n",
      "Epoch 355/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0776\n",
      "Epoch 356/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0780\n",
      "Epoch 357/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0766\n",
      "Epoch 358/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0759\n",
      "Epoch 359/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0772\n",
      "Epoch 360/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0774\n",
      "Epoch 361/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0769\n",
      "Epoch 362/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0754\n",
      "Epoch 363/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0758 - val_loss: 0.0761\n",
      "Epoch 364/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0756 - val_loss: 0.0790\n",
      "Epoch 365/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0783\n",
      "Epoch 366/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0756 - val_loss: 0.0764\n",
      "Epoch 367/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0756 - val_loss: 0.0770\n",
      "Epoch 368/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0784\n",
      "Epoch 369/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0766\n",
      "Epoch 370/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0754 - val_loss: 0.0767\n",
      "Epoch 371/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0787\n",
      "Epoch 372/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0757\n",
      "Epoch 373/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0757 - val_loss: 0.0762\n",
      "Epoch 374/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0782\n",
      "Epoch 375/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0769\n",
      "Epoch 376/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0792\n",
      "Epoch 377/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0772\n",
      "Epoch 378/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0771\n",
      "Epoch 379/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0780\n",
      "Epoch 380/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0788\n",
      "Epoch 381/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0771\n",
      "Epoch 382/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0763\n",
      "Epoch 383/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0754\n",
      "Epoch 384/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0792\n",
      "Epoch 385/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0754\n",
      "Epoch 386/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0766\n",
      "Epoch 387/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0760\n",
      "Epoch 388/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0792\n",
      "Epoch 389/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0772\n",
      "Epoch 390/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0760\n",
      "Epoch 391/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0755 - val_loss: 0.0780\n",
      "Epoch 392/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0753 - val_loss: 0.0761\n",
      "Epoch 393/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0755 - val_loss: 0.0759\n",
      "Epoch 394/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0754 - val_loss: 0.0762\n",
      "Epoch 395/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0760\n",
      "Epoch 396/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0784\n",
      "Epoch 397/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0777\n",
      "Epoch 398/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0767\n",
      "Epoch 399/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0789\n",
      "Epoch 400/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0760\n",
      "Epoch 401/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0748\n",
      "Epoch 402/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0771\n",
      "Epoch 403/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0766\n",
      "Epoch 404/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0765\n",
      "Epoch 405/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0775\n",
      "Epoch 406/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0780\n",
      "Epoch 407/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0756\n",
      "Epoch 408/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0757\n",
      "Epoch 409/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0754 - val_loss: 0.0761\n",
      "Epoch 410/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0772\n",
      "Epoch 411/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0766\n",
      "Epoch 412/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0772\n",
      "Epoch 413/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0764\n",
      "Epoch 414/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0775\n",
      "Epoch 415/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0755\n",
      "Epoch 416/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0781\n",
      "Epoch 417/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0773\n",
      "Epoch 418/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0753 - val_loss: 0.0777\n",
      "Epoch 419/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0796\n",
      "Epoch 420/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0777\n",
      "Epoch 421/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0771\n",
      "Epoch 422/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0777\n",
      "Epoch 423/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0753 - val_loss: 0.0769\n",
      "Epoch 424/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0768\n",
      "Epoch 425/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0775\n",
      "Epoch 426/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0764\n",
      "Epoch 427/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0768\n",
      "Epoch 428/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0752 - val_loss: 0.0749\n",
      "Epoch 429/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0751 - val_loss: 0.0770\n",
      "Epoch 430/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0753 - val_loss: 0.0820\n",
      "Epoch 431/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0751 - val_loss: 0.0783\n",
      "Epoch 432/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0753 - val_loss: 0.0781\n",
      "Epoch 433/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0791\n",
      "Epoch 434/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0761\n",
      "Epoch 435/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0770\n",
      "Epoch 436/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0763\n",
      "Epoch 437/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0771\n",
      "Epoch 438/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0768\n",
      "Epoch 439/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0805\n",
      "Epoch 440/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0755 - val_loss: 0.0806\n",
      "Epoch 441/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0762\n",
      "Epoch 442/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0784\n",
      "Epoch 443/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0747\n",
      "Epoch 444/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0778\n",
      "Epoch 445/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0769\n",
      "Epoch 446/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0771\n",
      "Epoch 447/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0774\n",
      "Epoch 448/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0765\n",
      "Epoch 449/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0770\n",
      "Epoch 450/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0753\n",
      "Epoch 451/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0781\n",
      "Epoch 452/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0756\n",
      "Epoch 453/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0787\n",
      "Epoch 454/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0758\n",
      "Epoch 455/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0761\n",
      "Epoch 456/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0769\n",
      "Epoch 457/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0760\n",
      "Epoch 458/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0762\n",
      "Epoch 459/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0762\n",
      "Epoch 460/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0845\n",
      "Epoch 461/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0751 - val_loss: 0.0769\n",
      "Epoch 462/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0766\n",
      "Epoch 463/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0776\n",
      "Epoch 464/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0756\n",
      "Epoch 465/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0779\n",
      "Epoch 466/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0779\n",
      "Epoch 467/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0770\n",
      "Epoch 468/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0752 - val_loss: 0.0765\n",
      "Epoch 469/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0758\n",
      "Epoch 470/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0762\n",
      "Epoch 471/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0799\n",
      "Epoch 472/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0755\n",
      "Epoch 473/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0746 - val_loss: 0.0778\n",
      "Epoch 474/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0776\n",
      "Epoch 475/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0758\n",
      "Epoch 476/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0754\n",
      "Epoch 477/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0777\n",
      "Epoch 478/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0790\n",
      "Epoch 479/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0750 - val_loss: 0.0768\n",
      "Epoch 480/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0770\n",
      "Epoch 481/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0753\n",
      "Epoch 482/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0763\n",
      "Epoch 483/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0758\n",
      "Epoch 484/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0764\n",
      "Epoch 485/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0779\n",
      "Epoch 486/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0750 - val_loss: 0.0767\n",
      "Epoch 487/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0767\n",
      "Epoch 488/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0746\n",
      "Epoch 489/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0749 - val_loss: 0.0756\n",
      "Epoch 490/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0749 - val_loss: 0.0798\n",
      "Epoch 491/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0749 - val_loss: 0.0755\n",
      "Epoch 492/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0749 - val_loss: 0.0758\n",
      "Epoch 493/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0752\n",
      "Epoch 494/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0761\n",
      "Epoch 495/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0767\n",
      "Epoch 496/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0749 - val_loss: 0.0771\n",
      "Epoch 497/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0769\n",
      "Epoch 498/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0751\n",
      "Epoch 499/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0774\n",
      "Epoch 500/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0751\n",
      "Epoch 501/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0758\n",
      "Epoch 502/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0749 - val_loss: 0.0762\n",
      "Epoch 503/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0749 - val_loss: 0.0773\n",
      "Epoch 504/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0771\n",
      "Epoch 505/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0787\n",
      "Epoch 506/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0816\n",
      "Epoch 507/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0746 - val_loss: 0.0790\n",
      "Epoch 508/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0748 - val_loss: 0.0753\n",
      "Epoch 509/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0772\n",
      "Epoch 510/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0753\n",
      "Epoch 511/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0752\n",
      "Epoch 512/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0754\n",
      "Epoch 513/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0783\n",
      "Epoch 514/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0755\n",
      "Epoch 515/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0759\n",
      "Epoch 516/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0773\n",
      "Epoch 517/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0748\n",
      "Epoch 518/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0754\n",
      "Epoch 519/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0746 - val_loss: 0.0758\n",
      "Epoch 520/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0770\n",
      "Epoch 521/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0755\n",
      "Epoch 522/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0771\n",
      "Epoch 523/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0775\n",
      "Epoch 524/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0768\n",
      "Epoch 525/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0746 - val_loss: 0.0761\n",
      "Epoch 526/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0746 - val_loss: 0.0757\n",
      "Epoch 527/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0754\n",
      "Epoch 528/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0744 - val_loss: 0.0758\n",
      "Epoch 529/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0748 - val_loss: 0.0761\n",
      "Epoch 530/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0747 - val_loss: 0.0767\n",
      "Epoch 531/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0745 - val_loss: 0.0784\n",
      "Epoch 532/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0746 - val_loss: 0.0765\n",
      "Epoch 533/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0746 - val_loss: 0.0762\n",
      "Epoch 534/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0745 - val_loss: 0.0761\n",
      "Epoch 535/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0770\n",
      "Epoch 536/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0762\n",
      "Epoch 537/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0747 - val_loss: 0.0762\n",
      "Epoch 538/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0765\n",
      "Epoch 539/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0771\n",
      "Epoch 540/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0746 - val_loss: 0.0763\n",
      "Epoch 541/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0776\n",
      "Epoch 542/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0747 - val_loss: 0.0752\n",
      "Epoch 543/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0756\n",
      "Epoch 544/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0745 - val_loss: 0.0772\n",
      "Epoch 545/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0787\n",
      "Epoch 546/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0758\n",
      "Epoch 547/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0768\n",
      "Epoch 548/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0736\n",
      "Epoch 549/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0769\n",
      "Epoch 550/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0752\n",
      "Epoch 551/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0763\n",
      "Epoch 552/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0747\n",
      "Epoch 553/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0762\n",
      "Epoch 554/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0811\n",
      "Epoch 555/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0756\n",
      "Epoch 556/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0745\n",
      "Epoch 557/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0743 - val_loss: 0.0764\n",
      "Epoch 558/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0745 - val_loss: 0.0748\n",
      "Epoch 559/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0761\n",
      "Epoch 560/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0770\n",
      "Epoch 561/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0743 - val_loss: 0.0765\n",
      "Epoch 562/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0744 - val_loss: 0.0786\n",
      "Epoch 563/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0782\n",
      "Epoch 564/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0769\n",
      "Epoch 565/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0759\n",
      "Epoch 566/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0802\n",
      "Epoch 567/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0744 - val_loss: 0.0744\n",
      "Epoch 568/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0744 - val_loss: 0.0754\n",
      "Epoch 569/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0768\n",
      "Epoch 570/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0750\n",
      "Epoch 571/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.0744 - val_loss: 0.0771\n",
      "Epoch 572/600\n",
      "3035/3035 [==============================] - 13s 4ms/step - loss: 0.0744 - val_loss: 0.0755\n",
      "Epoch 573/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0746 - val_loss: 0.0787\n",
      "Epoch 574/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0775\n",
      "Epoch 575/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0751\n",
      "Epoch 576/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0764\n",
      "Epoch 577/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0751\n",
      "Epoch 578/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0752\n",
      "Epoch 579/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0750\n",
      "Epoch 580/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0808\n",
      "Epoch 581/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0752\n",
      "Epoch 582/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0745 - val_loss: 0.0784\n",
      "Epoch 583/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0761\n",
      "Epoch 584/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0752\n",
      "Epoch 585/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0742 - val_loss: 0.0800\n",
      "Epoch 586/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0741 - val_loss: 0.0757\n",
      "Epoch 587/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0754\n",
      "Epoch 588/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0773\n",
      "Epoch 589/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0743 - val_loss: 0.0774\n",
      "Epoch 590/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0740 - val_loss: 0.0755\n",
      "Epoch 591/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0741 - val_loss: 0.0749\n",
      "Epoch 592/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0775\n",
      "Epoch 593/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0742 - val_loss: 0.0761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 594/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0741 - val_loss: 0.0755\n",
      "Epoch 595/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0755\n",
      "Epoch 596/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0763\n",
      "Epoch 597/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0776\n",
      "Epoch 598/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0745\n",
      "Epoch 599/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0742 - val_loss: 0.0769\n",
      "Epoch 600/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0741 - val_loss: 0.0754\n",
      "1124/1124 [==============================] - 2s 2ms/step\n",
      "\n",
      "Training window:  3\n",
      "Epoch 1/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.1269 - val_loss: 0.1171\n",
      "Epoch 2/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1126 - val_loss: 0.1096\n",
      "Epoch 3/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1091 - val_loss: 0.1082\n",
      "Epoch 4/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1070 - val_loss: 0.1093\n",
      "Epoch 5/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.1053 - val_loss: 0.1042\n",
      "Epoch 6/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1040 - val_loss: 0.1031\n",
      "Epoch 7/600\n",
      "3035/3035 [==============================] - 11s 3ms/step - loss: 0.1030 - val_loss: 0.1047\n",
      "Epoch 8/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1022 - val_loss: 0.1019\n",
      "Epoch 9/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.1015 - val_loss: 0.1067\n",
      "Epoch 10/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.1005 - val_loss: 0.0987\n",
      "Epoch 11/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0997 - val_loss: 0.0989\n",
      "Epoch 12/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0990 - val_loss: 0.1003\n",
      "Epoch 13/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0985 - val_loss: 0.0970\n",
      "Epoch 14/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0977 - val_loss: 0.1006\n",
      "Epoch 15/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0970 - val_loss: 0.0957\n",
      "Epoch 16/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0963 - val_loss: 0.0963\n",
      "Epoch 17/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0961 - val_loss: 0.0967\n",
      "Epoch 18/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0957 - val_loss: 0.0948\n",
      "Epoch 19/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0952 - val_loss: 0.0936\n",
      "Epoch 20/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0946 - val_loss: 0.0961\n",
      "Epoch 21/600\n",
      "3035/3035 [==============================] - 11s 4ms/step - loss: 0.0942 - val_loss: 0.1003\n",
      "Epoch 22/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0937 - val_loss: 0.0930\n",
      "Epoch 23/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0932 - val_loss: 0.0987\n",
      "Epoch 24/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
      "Epoch 25/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0923 - val_loss: 0.0914\n",
      "Epoch 26/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0920 - val_loss: 0.0912\n",
      "Epoch 27/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0918 - val_loss: 0.0949\n",
      "Epoch 28/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0913 - val_loss: 0.0931\n",
      "Epoch 29/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0908 - val_loss: 0.0901\n",
      "Epoch 30/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0904 - val_loss: 0.0900\n",
      "Epoch 31/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0898 - val_loss: 0.0902\n",
      "Epoch 32/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0897 - val_loss: 0.0923\n",
      "Epoch 33/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0894 - val_loss: 0.0905\n",
      "Epoch 34/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0889 - val_loss: 0.0886\n",
      "Epoch 35/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0884 - val_loss: 0.0916\n",
      "Epoch 36/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0879 - val_loss: 0.0887\n",
      "Epoch 37/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0874 - val_loss: 0.0914\n",
      "Epoch 38/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0870 - val_loss: 0.0890\n",
      "Epoch 39/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0865 - val_loss: 0.0859\n",
      "Epoch 40/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0863 - val_loss: 0.0883\n",
      "Epoch 41/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0856 - val_loss: 0.0868\n",
      "Epoch 42/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0853 - val_loss: 0.0869\n",
      "Epoch 43/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0848 - val_loss: 0.0862\n",
      "Epoch 44/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0844 - val_loss: 0.0846\n",
      "Epoch 45/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0840 - val_loss: 0.0828\n",
      "Epoch 46/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0836 - val_loss: 0.0837\n",
      "Epoch 47/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0834 - val_loss: 0.0859\n",
      "Epoch 48/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0832 - val_loss: 0.0821\n",
      "Epoch 49/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0828 - val_loss: 0.0838\n",
      "Epoch 50/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0826 - val_loss: 0.0813\n",
      "Epoch 51/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0827 - val_loss: 0.0887\n",
      "Epoch 52/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0824 - val_loss: 0.0836\n",
      "Epoch 53/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0819 - val_loss: 0.0817\n",
      "Epoch 54/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0819 - val_loss: 0.0813\n",
      "Epoch 55/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0815 - val_loss: 0.0824\n",
      "Epoch 56/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0815 - val_loss: 0.0805\n",
      "Epoch 57/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0813 - val_loss: 0.0812\n",
      "Epoch 58/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0812 - val_loss: 0.0809\n",
      "Epoch 59/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0808 - val_loss: 0.0813\n",
      "Epoch 60/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0806 - val_loss: 0.0793\n",
      "Epoch 61/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0805 - val_loss: 0.0796\n",
      "Epoch 62/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0805 - val_loss: 0.0796\n",
      "Epoch 63/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0805 - val_loss: 0.0806\n",
      "Epoch 64/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0801 - val_loss: 0.0819\n",
      "Epoch 65/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0802 - val_loss: 0.0806\n",
      "Epoch 66/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0796 - val_loss: 0.0803\n",
      "Epoch 67/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0796 - val_loss: 0.0800\n",
      "Epoch 68/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0794 - val_loss: 0.0793\n",
      "Epoch 69/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0793 - val_loss: 0.0805\n",
      "Epoch 70/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0790 - val_loss: 0.0815\n",
      "Epoch 71/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0789 - val_loss: 0.0792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0788 - val_loss: 0.0797\n",
      "Epoch 73/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0787 - val_loss: 0.0787\n",
      "Epoch 74/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0785 - val_loss: 0.0792\n",
      "Epoch 75/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0784 - val_loss: 0.0795\n",
      "Epoch 76/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0783 - val_loss: 0.0765\n",
      "Epoch 77/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0781 - val_loss: 0.0816\n",
      "Epoch 78/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0779 - val_loss: 0.0791\n",
      "Epoch 79/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0777 - val_loss: 0.0783\n",
      "Epoch 80/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0778 - val_loss: 0.0838\n",
      "Epoch 81/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0777 - val_loss: 0.0780\n",
      "Epoch 82/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0773 - val_loss: 0.0779\n",
      "Epoch 83/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0772 - val_loss: 0.0790\n",
      "Epoch 84/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0772 - val_loss: 0.0770\n",
      "Epoch 85/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0769 - val_loss: 0.0815\n",
      "Epoch 86/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0768 - val_loss: 0.0760\n",
      "Epoch 87/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0766 - val_loss: 0.0764\n",
      "Epoch 88/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0765 - val_loss: 0.0756\n",
      "Epoch 89/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0767 - val_loss: 0.0785\n",
      "Epoch 90/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0763 - val_loss: 0.0775\n",
      "Epoch 91/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0763 - val_loss: 0.0769\n",
      "Epoch 92/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0763 - val_loss: 0.0763\n",
      "Epoch 93/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0760 - val_loss: 0.0757\n",
      "Epoch 94/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0760 - val_loss: 0.0753\n",
      "Epoch 95/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0759 - val_loss: 0.0763\n",
      "Epoch 96/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0757 - val_loss: 0.0745\n",
      "Epoch 97/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0756 - val_loss: 0.0758\n",
      "Epoch 98/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0754 - val_loss: 0.0775\n",
      "Epoch 99/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0752 - val_loss: 0.0783\n",
      "Epoch 100/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0755 - val_loss: 0.0755\n",
      "Epoch 101/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0751 - val_loss: 0.0766\n",
      "Epoch 102/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0749 - val_loss: 0.0770\n",
      "Epoch 103/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0750 - val_loss: 0.0754\n",
      "Epoch 104/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0757\n",
      "Epoch 105/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0748 - val_loss: 0.0753\n",
      "Epoch 106/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0746 - val_loss: 0.0768\n",
      "Epoch 107/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0744 - val_loss: 0.0757\n",
      "Epoch 108/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0746 - val_loss: 0.0785\n",
      "Epoch 109/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0743 - val_loss: 0.0752\n",
      "Epoch 110/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0743 - val_loss: 0.0757\n",
      "Epoch 111/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0741 - val_loss: 0.0762\n",
      "Epoch 112/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0743 - val_loss: 0.0737\n",
      "Epoch 113/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0741 - val_loss: 0.0750\n",
      "Epoch 114/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0740 - val_loss: 0.0754\n",
      "Epoch 115/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0741 - val_loss: 0.0753\n",
      "Epoch 116/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0739 - val_loss: 0.0780\n",
      "Epoch 117/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0736 - val_loss: 0.0741\n",
      "Epoch 118/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0735 - val_loss: 0.0755\n",
      "Epoch 119/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0737 - val_loss: 0.0743\n",
      "Epoch 120/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0735 - val_loss: 0.0760\n",
      "Epoch 121/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0734 - val_loss: 0.0775\n",
      "Epoch 122/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0734 - val_loss: 0.0754\n",
      "Epoch 123/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0734 - val_loss: 0.0746\n",
      "Epoch 124/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0733 - val_loss: 0.0765\n",
      "Epoch 125/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0733 - val_loss: 0.0740\n",
      "Epoch 126/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0732 - val_loss: 0.0726\n",
      "Epoch 127/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0730 - val_loss: 0.0765\n",
      "Epoch 128/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0729 - val_loss: 0.0740\n",
      "Epoch 129/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0729 - val_loss: 0.0756\n",
      "Epoch 130/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0731 - val_loss: 0.0738\n",
      "Epoch 131/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0730 - val_loss: 0.0728\n",
      "Epoch 132/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0725 - val_loss: 0.0808\n",
      "Epoch 133/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0726 - val_loss: 0.0743\n",
      "Epoch 134/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0724 - val_loss: 0.0742\n",
      "Epoch 135/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0723 - val_loss: 0.0722\n",
      "Epoch 136/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0724 - val_loss: 0.0734\n",
      "Epoch 137/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0723 - val_loss: 0.0733\n",
      "Epoch 138/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0722 - val_loss: 0.0730\n",
      "Epoch 139/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0720 - val_loss: 0.0727\n",
      "Epoch 140/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0722 - val_loss: 0.0727\n",
      "Epoch 141/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0719 - val_loss: 0.0731\n",
      "Epoch 142/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0720 - val_loss: 0.0739\n",
      "Epoch 143/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0718 - val_loss: 0.0752\n",
      "Epoch 144/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0720 - val_loss: 0.0735\n",
      "Epoch 145/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0717 - val_loss: 0.0726\n",
      "Epoch 146/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0716 - val_loss: 0.0727\n",
      "Epoch 147/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0716 - val_loss: 0.0731\n",
      "Epoch 148/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0715 - val_loss: 0.0738\n",
      "Epoch 149/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0716 - val_loss: 0.0734\n",
      "Epoch 150/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0713 - val_loss: 0.0717\n",
      "Epoch 151/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0713 - val_loss: 0.0734\n",
      "Epoch 152/600\n",
      "3035/3035 [==============================] - 9s 3ms/step - loss: 0.0711 - val_loss: 0.0748\n",
      "Epoch 153/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0713 - val_loss: 0.0710\n",
      "Epoch 154/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0710 - val_loss: 0.0713\n",
      "Epoch 155/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0711 - val_loss: 0.0733\n",
      "Epoch 156/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0707 - val_loss: 0.0740\n",
      "Epoch 157/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0708 - val_loss: 0.0731\n",
      "Epoch 158/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0706 - val_loss: 0.0740\n",
      "Epoch 159/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0706 - val_loss: 0.0707\n",
      "Epoch 160/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0707 - val_loss: 0.0717\n",
      "Epoch 161/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0707 - val_loss: 0.0711\n",
      "Epoch 162/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0703 - val_loss: 0.0759\n",
      "Epoch 163/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0702 - val_loss: 0.0744\n",
      "Epoch 164/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0703 - val_loss: 0.0710\n",
      "Epoch 165/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0702 - val_loss: 0.0707\n",
      "Epoch 166/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0701 - val_loss: 0.0716\n",
      "Epoch 167/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0700 - val_loss: 0.0718\n",
      "Epoch 168/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0701 - val_loss: 0.0715\n",
      "Epoch 169/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0701 - val_loss: 0.0703\n",
      "Epoch 170/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0698 - val_loss: 0.0724\n",
      "Epoch 171/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0698 - val_loss: 0.0701\n",
      "Epoch 172/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0696 - val_loss: 0.0707\n",
      "Epoch 173/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0698 - val_loss: 0.0700\n",
      "Epoch 174/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0698 - val_loss: 0.0728\n",
      "Epoch 175/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0695 - val_loss: 0.0777\n",
      "Epoch 176/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0694 - val_loss: 0.0735\n",
      "Epoch 177/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0693 - val_loss: 0.0710\n",
      "Epoch 178/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0696 - val_loss: 0.0694\n",
      "Epoch 179/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0693 - val_loss: 0.0689\n",
      "Epoch 180/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0694 - val_loss: 0.0697\n",
      "Epoch 181/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0693 - val_loss: 0.0717\n",
      "Epoch 182/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0693 - val_loss: 0.0703\n",
      "Epoch 183/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0691 - val_loss: 0.0712\n",
      "Epoch 184/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0689 - val_loss: 0.0734\n",
      "Epoch 185/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0691 - val_loss: 0.0689\n",
      "Epoch 186/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0690 - val_loss: 0.0701\n",
      "Epoch 187/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0687 - val_loss: 0.0703\n",
      "Epoch 188/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0687 - val_loss: 0.0712\n",
      "Epoch 189/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0686 - val_loss: 0.0694\n",
      "Epoch 190/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0687 - val_loss: 0.0689\n",
      "Epoch 191/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0688 - val_loss: 0.0706\n",
      "Epoch 192/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0685 - val_loss: 0.0705\n",
      "Epoch 193/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0687 - val_loss: 0.0723\n",
      "Epoch 194/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0685 - val_loss: 0.0716\n",
      "Epoch 195/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0685 - val_loss: 0.0712\n",
      "Epoch 196/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0688 - val_loss: 0.0706\n",
      "Epoch 197/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0683 - val_loss: 0.0704\n",
      "Epoch 198/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0682 - val_loss: 0.0676\n",
      "Epoch 199/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0683 - val_loss: 0.0704\n",
      "Epoch 200/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0682 - val_loss: 0.0696\n",
      "Epoch 201/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 202/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0680 - val_loss: 0.0697\n",
      "Epoch 203/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0680 - val_loss: 0.0662\n",
      "Epoch 204/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0678 - val_loss: 0.0710\n",
      "Epoch 205/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0680 - val_loss: 0.0685\n",
      "Epoch 206/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0680 - val_loss: 0.0712\n",
      "Epoch 207/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0678 - val_loss: 0.0674\n",
      "Epoch 208/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0678 - val_loss: 0.0695\n",
      "Epoch 209/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0677 - val_loss: 0.0715\n",
      "Epoch 210/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0676 - val_loss: 0.0679\n",
      "Epoch 211/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0674 - val_loss: 0.0713\n",
      "Epoch 212/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0677 - val_loss: 0.0687\n",
      "Epoch 213/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0673 - val_loss: 0.0694\n",
      "Epoch 214/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0677 - val_loss: 0.0740\n",
      "Epoch 215/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0677 - val_loss: 0.0694\n",
      "Epoch 216/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0676 - val_loss: 0.0709\n",
      "Epoch 217/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0672 - val_loss: 0.0681\n",
      "Epoch 218/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0674 - val_loss: 0.0689\n",
      "Epoch 219/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0673 - val_loss: 0.0663\n",
      "Epoch 220/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0670 - val_loss: 0.0680\n",
      "Epoch 221/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0673 - val_loss: 0.0670\n",
      "Epoch 222/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0671 - val_loss: 0.0707\n",
      "Epoch 223/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0673 - val_loss: 0.0702\n",
      "Epoch 224/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0669 - val_loss: 0.0677\n",
      "Epoch 225/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0671 - val_loss: 0.0683\n",
      "Epoch 226/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0670 - val_loss: 0.0658\n",
      "Epoch 227/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0670 - val_loss: 0.0697\n",
      "Epoch 228/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0669 - val_loss: 0.0682\n",
      "Epoch 229/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0668 - val_loss: 0.0692\n",
      "Epoch 230/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0669 - val_loss: 0.0714\n",
      "Epoch 231/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0667 - val_loss: 0.0680\n",
      "Epoch 232/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0667 - val_loss: 0.0690\n",
      "Epoch 233/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0665 - val_loss: 0.0687\n",
      "Epoch 234/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0666 - val_loss: 0.0667\n",
      "Epoch 235/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0665 - val_loss: 0.0700\n",
      "Epoch 236/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0666 - val_loss: 0.0689\n",
      "Epoch 237/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0665 - val_loss: 0.0690\n",
      "Epoch 238/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0663 - val_loss: 0.0695\n",
      "Epoch 239/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0661 - val_loss: 0.0659\n",
      "Epoch 240/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0663 - val_loss: 0.0679\n",
      "Epoch 241/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0664 - val_loss: 0.0688\n",
      "Epoch 242/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0661 - val_loss: 0.0667\n",
      "Epoch 243/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0659 - val_loss: 0.0677\n",
      "Epoch 244/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0661 - val_loss: 0.0667\n",
      "Epoch 245/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0659 - val_loss: 0.0665\n",
      "Epoch 246/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0658 - val_loss: 0.0699\n",
      "Epoch 247/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0658 - val_loss: 0.0658\n",
      "Epoch 248/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0658 - val_loss: 0.0647\n",
      "Epoch 249/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0658 - val_loss: 0.0659\n",
      "Epoch 250/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0656 - val_loss: 0.0667\n",
      "Epoch 251/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0658 - val_loss: 0.0702\n",
      "Epoch 252/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0657 - val_loss: 0.0680\n",
      "Epoch 253/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0655 - val_loss: 0.0687\n",
      "Epoch 254/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0655 - val_loss: 0.0654\n",
      "Epoch 255/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0656\n",
      "Epoch 256/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0657 - val_loss: 0.0656\n",
      "Epoch 257/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0664\n",
      "Epoch 258/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0655 - val_loss: 0.0680\n",
      "Epoch 259/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0654 - val_loss: 0.0666\n",
      "Epoch 260/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0654 - val_loss: 0.0690\n",
      "Epoch 261/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0655\n",
      "Epoch 262/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0649 - val_loss: 0.0649\n",
      "Epoch 263/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0652 - val_loss: 0.0649\n",
      "Epoch 264/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0650 - val_loss: 0.0654\n",
      "Epoch 265/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0654\n",
      "Epoch 266/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0650 - val_loss: 0.0639\n",
      "Epoch 267/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0651 - val_loss: 0.0662\n",
      "Epoch 268/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0650 - val_loss: 0.0676\n",
      "Epoch 269/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0653 - val_loss: 0.0649\n",
      "Epoch 270/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0648 - val_loss: 0.0665\n",
      "Epoch 271/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0648 - val_loss: 0.0652\n",
      "Epoch 272/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0648 - val_loss: 0.0658\n",
      "Epoch 273/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0646 - val_loss: 0.0660\n",
      "Epoch 274/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0649 - val_loss: 0.0649\n",
      "Epoch 275/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0646 - val_loss: 0.0633\n",
      "Epoch 276/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0647 - val_loss: 0.0679\n",
      "Epoch 277/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0646 - val_loss: 0.0658\n",
      "Epoch 278/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0645 - val_loss: 0.0645\n",
      "Epoch 279/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0645 - val_loss: 0.0658\n",
      "Epoch 280/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0645 - val_loss: 0.0647\n",
      "Epoch 281/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0644 - val_loss: 0.0729\n",
      "Epoch 282/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0646 - val_loss: 0.0650\n",
      "Epoch 283/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0642 - val_loss: 0.0636\n",
      "Epoch 284/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0643 - val_loss: 0.0659\n",
      "Epoch 285/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0643 - val_loss: 0.0661\n",
      "Epoch 286/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0643 - val_loss: 0.0638\n",
      "Epoch 287/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0640 - val_loss: 0.0633\n",
      "Epoch 288/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0643 - val_loss: 0.0634\n",
      "Epoch 289/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0639 - val_loss: 0.0667\n",
      "Epoch 290/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0640 - val_loss: 0.0648\n",
      "Epoch 291/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0638 - val_loss: 0.0654\n",
      "Epoch 292/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0639 - val_loss: 0.0648\n",
      "Epoch 293/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0640 - val_loss: 0.0661\n",
      "Epoch 294/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0638 - val_loss: 0.0645\n",
      "Epoch 295/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0638 - val_loss: 0.0645\n",
      "Epoch 296/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0638 - val_loss: 0.0637\n",
      "Epoch 297/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0636 - val_loss: 0.0663\n",
      "Epoch 298/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0636 - val_loss: 0.0646\n",
      "Epoch 299/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0637 - val_loss: 0.0639\n",
      "Epoch 300/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0634 - val_loss: 0.0652\n",
      "Epoch 301/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0632 - val_loss: 0.0616\n",
      "Epoch 302/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0634 - val_loss: 0.0625\n",
      "Epoch 303/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0632 - val_loss: 0.0635\n",
      "Epoch 304/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0630 - val_loss: 0.0671\n",
      "Epoch 305/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0634 - val_loss: 0.0657\n",
      "Epoch 306/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0635 - val_loss: 0.0645\n",
      "Epoch 307/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0630 - val_loss: 0.0647\n",
      "Epoch 308/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0630 - val_loss: 0.0642\n",
      "Epoch 309/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0629 - val_loss: 0.0632\n",
      "Epoch 310/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0628 - val_loss: 0.0657\n",
      "Epoch 311/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0630 - val_loss: 0.0652\n",
      "Epoch 312/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0629 - val_loss: 0.0622\n",
      "Epoch 313/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0627 - val_loss: 0.0651\n",
      "Epoch 314/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0629 - val_loss: 0.0627\n",
      "Epoch 315/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0627 - val_loss: 0.0624\n",
      "Epoch 316/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0626 - val_loss: 0.0621\n",
      "Epoch 317/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0627 - val_loss: 0.0671\n",
      "Epoch 318/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0628 - val_loss: 0.0627\n",
      "Epoch 319/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0640\n",
      "Epoch 320/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0643\n",
      "Epoch 321/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0627\n",
      "Epoch 322/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0612\n",
      "Epoch 323/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0627 - val_loss: 0.0621\n",
      "Epoch 324/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0624 - val_loss: 0.0610\n",
      "Epoch 325/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0625 - val_loss: 0.0631\n",
      "Epoch 326/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0624 - val_loss: 0.0612\n",
      "Epoch 327/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0622 - val_loss: 0.0625\n",
      "Epoch 328/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0623 - val_loss: 0.0634\n",
      "Epoch 329/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0624 - val_loss: 0.0603\n",
      "Epoch 330/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0622 - val_loss: 0.0623\n",
      "Epoch 331/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0621 - val_loss: 0.0668\n",
      "Epoch 332/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0623 - val_loss: 0.0637\n",
      "Epoch 333/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0624 - val_loss: 0.0629\n",
      "Epoch 334/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0623 - val_loss: 0.0648\n",
      "Epoch 335/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0620 - val_loss: 0.0634\n",
      "Epoch 336/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0619 - val_loss: 0.0627\n",
      "Epoch 337/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0622 - val_loss: 0.0627\n",
      "Epoch 338/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0618 - val_loss: 0.0617\n",
      "Epoch 339/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0619 - val_loss: 0.0619\n",
      "Epoch 340/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0620 - val_loss: 0.0623\n",
      "Epoch 341/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0618 - val_loss: 0.0624\n",
      "Epoch 342/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0622 - val_loss: 0.0618\n",
      "Epoch 343/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0616 - val_loss: 0.0637\n",
      "Epoch 344/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0618 - val_loss: 0.0628\n",
      "Epoch 345/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0620 - val_loss: 0.0633\n",
      "Epoch 346/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0617 - val_loss: 0.0626\n",
      "Epoch 347/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0617 - val_loss: 0.0639\n",
      "Epoch 348/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0618 - val_loss: 0.0630\n",
      "Epoch 349/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0619 - val_loss: 0.0642\n",
      "Epoch 350/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0615 - val_loss: 0.0634\n",
      "Epoch 351/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0618 - val_loss: 0.0636\n",
      "Epoch 352/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0616 - val_loss: 0.0631\n",
      "Epoch 353/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0624\n",
      "Epoch 354/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0616 - val_loss: 0.0636\n",
      "Epoch 355/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0617 - val_loss: 0.0617\n",
      "Epoch 356/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0616 - val_loss: 0.0642\n",
      "Epoch 357/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0618\n",
      "Epoch 358/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0614 - val_loss: 0.0620\n",
      "Epoch 359/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0615 - val_loss: 0.0625\n",
      "Epoch 360/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0605\n",
      "Epoch 361/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0606\n",
      "Epoch 362/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0612 - val_loss: 0.0611\n",
      "Epoch 363/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0617\n",
      "Epoch 364/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0626\n",
      "Epoch 365/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0615 - val_loss: 0.0622\n",
      "Epoch 366/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0630\n",
      "Epoch 367/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0615 - val_loss: 0.0626\n",
      "Epoch 368/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0615\n",
      "Epoch 369/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0644\n",
      "Epoch 370/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0616\n",
      "Epoch 371/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0603\n",
      "Epoch 372/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0612 - val_loss: 0.0655\n",
      "Epoch 373/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0614\n",
      "Epoch 374/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0611 - val_loss: 0.0598\n",
      "Epoch 375/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0613 - val_loss: 0.0595\n",
      "Epoch 376/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0614 - val_loss: 0.0637\n",
      "Epoch 377/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0606\n",
      "Epoch 378/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0612 - val_loss: 0.0664\n",
      "Epoch 379/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0637\n",
      "Epoch 380/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0611 - val_loss: 0.0629\n",
      "Epoch 381/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0674\n",
      "Epoch 382/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0647\n",
      "Epoch 383/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0612\n",
      "Epoch 384/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0612 - val_loss: 0.0644\n",
      "Epoch 385/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0603\n",
      "Epoch 386/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0623\n",
      "Epoch 387/600\n",
      "3035/3035 [==============================] - 5s 1ms/step - loss: 0.0609 - val_loss: 0.0626\n",
      "Epoch 388/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0623\n",
      "Epoch 389/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0611 - val_loss: 0.0637\n",
      "Epoch 390/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0628\n",
      "Epoch 391/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0621\n",
      "Epoch 392/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0636\n",
      "Epoch 393/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0612\n",
      "Epoch 394/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0610 - val_loss: 0.0600\n",
      "Epoch 395/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0610\n",
      "Epoch 396/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0621\n",
      "Epoch 397/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0608\n",
      "Epoch 398/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0602\n",
      "Epoch 399/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0603\n",
      "Epoch 400/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0620\n",
      "Epoch 401/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0626\n",
      "Epoch 402/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0626\n",
      "Epoch 403/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0606 - val_loss: 0.0649\n",
      "Epoch 404/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0662\n",
      "Epoch 405/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0609\n",
      "Epoch 406/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0603\n",
      "Epoch 407/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0625\n",
      "Epoch 408/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0594\n",
      "Epoch 409/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0633\n",
      "Epoch 410/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0613\n",
      "Epoch 411/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0608\n",
      "Epoch 412/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0607 - val_loss: 0.0659\n",
      "Epoch 413/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0608 - val_loss: 0.0623\n",
      "Epoch 414/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0609 - val_loss: 0.0602\n",
      "Epoch 415/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0606 - val_loss: 0.0641\n",
      "Epoch 416/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0607 - val_loss: 0.0588\n",
      "Epoch 417/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0608 - val_loss: 0.0616\n",
      "Epoch 418/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0606 - val_loss: 0.0628\n",
      "Epoch 419/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0612\n",
      "Epoch 420/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 421/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0606 - val_loss: 0.0644\n",
      "Epoch 422/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0616\n",
      "Epoch 423/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0632\n",
      "Epoch 424/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0611\n",
      "Epoch 425/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0616\n",
      "Epoch 426/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0598\n",
      "Epoch 427/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0606\n",
      "Epoch 428/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0604 - val_loss: 0.0613\n",
      "Epoch 429/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0604 - val_loss: 0.0601\n",
      "Epoch 430/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0603 - val_loss: 0.0621\n",
      "Epoch 431/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0638\n",
      "Epoch 432/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0629\n",
      "Epoch 433/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0611\n",
      "Epoch 434/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0616\n",
      "Epoch 435/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0601\n",
      "Epoch 436/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0618\n",
      "Epoch 437/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0627\n",
      "Epoch 438/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0628\n",
      "Epoch 439/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0657\n",
      "Epoch 440/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0603 - val_loss: 0.0599\n",
      "Epoch 441/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0604 - val_loss: 0.0629\n",
      "Epoch 442/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0629\n",
      "Epoch 443/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0617\n",
      "Epoch 444/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0604 - val_loss: 0.0642\n",
      "Epoch 445/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0645\n",
      "Epoch 446/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0627\n",
      "Epoch 447/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0620\n",
      "Epoch 448/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0610\n",
      "Epoch 449/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0605 - val_loss: 0.0607\n",
      "Epoch 450/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0634\n",
      "Epoch 451/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0600 - val_loss: 0.0590\n",
      "Epoch 452/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0601 - val_loss: 0.0639\n",
      "Epoch 453/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0598\n",
      "Epoch 454/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0597\n",
      "Epoch 455/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0615\n",
      "Epoch 456/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0601 - val_loss: 0.0642\n",
      "Epoch 457/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0600 - val_loss: 0.0593\n",
      "Epoch 458/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0603 - val_loss: 0.0608\n",
      "Epoch 459/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0611\n",
      "Epoch 460/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0613\n",
      "Epoch 461/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0600 - val_loss: 0.0606\n",
      "Epoch 462/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0583\n",
      "Epoch 463/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0588\n",
      "Epoch 464/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0617\n",
      "Epoch 465/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0602 - val_loss: 0.0616\n",
      "Epoch 466/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0599\n",
      "Epoch 467/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0605\n",
      "Epoch 468/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0598 - val_loss: 0.0600\n",
      "Epoch 469/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0600 - val_loss: 0.0642\n",
      "Epoch 470/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0621\n",
      "Epoch 471/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 472/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0599 - val_loss: 0.0582\n",
      "Epoch 473/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0597 - val_loss: 0.0593\n",
      "Epoch 474/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0598 - val_loss: 0.0611\n",
      "Epoch 475/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0601 - val_loss: 0.0618\n",
      "Epoch 476/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 477/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0638\n",
      "Epoch 478/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0599 - val_loss: 0.0613\n",
      "Epoch 479/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0599 - val_loss: 0.0611\n",
      "Epoch 480/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0598 - val_loss: 0.0589\n",
      "Epoch 481/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0598 - val_loss: 0.0583\n",
      "Epoch 482/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0627\n",
      "Epoch 483/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0596 - val_loss: 0.0604\n",
      "Epoch 484/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0596 - val_loss: 0.0589\n",
      "Epoch 485/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0599 - val_loss: 0.0610\n",
      "Epoch 486/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0600\n",
      "Epoch 487/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0596 - val_loss: 0.0607\n",
      "Epoch 488/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0596 - val_loss: 0.0606\n",
      "Epoch 489/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0599 - val_loss: 0.0635\n",
      "Epoch 490/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0596 - val_loss: 0.0592\n",
      "Epoch 491/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0596 - val_loss: 0.0600\n",
      "Epoch 492/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0634\n",
      "Epoch 493/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0596 - val_loss: 0.0599\n",
      "Epoch 494/600\n",
      "3035/3035 [==============================] - 5s 2ms/step - loss: 0.0597 - val_loss: 0.0599\n",
      "Epoch 495/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0629\n",
      "Epoch 496/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0595 - val_loss: 0.0615\n",
      "Epoch 497/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0595 - val_loss: 0.0599\n",
      "Epoch 498/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0595 - val_loss: 0.0618\n",
      "Epoch 499/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0597 - val_loss: 0.0610\n",
      "Epoch 500/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0618\n",
      "Epoch 501/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 502/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0625\n",
      "Epoch 503/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0615\n",
      "Epoch 504/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0593 - val_loss: 0.0608\n",
      "Epoch 505/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0609\n",
      "Epoch 506/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0596 - val_loss: 0.0592\n",
      "Epoch 507/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0604\n",
      "Epoch 508/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0593 - val_loss: 0.0598\n",
      "Epoch 509/600\n",
      "3035/3035 [==============================] - 8s 3ms/step - loss: 0.0593 - val_loss: 0.0588\n",
      "Epoch 510/600\n",
      "3035/3035 [==============================] - 10s 3ms/step - loss: 0.0596 - val_loss: 0.0610\n",
      "Epoch 511/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0594 - val_loss: 0.0583\n",
      "Epoch 512/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0617\n",
      "Epoch 513/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 514/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0594\n",
      "Epoch 515/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0632\n",
      "Epoch 516/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0618\n",
      "Epoch 517/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0593 - val_loss: 0.0585\n",
      "Epoch 518/600\n",
      "3035/3035 [==============================] - 8s 2ms/step - loss: 0.0592 - val_loss: 0.0613\n",
      "Epoch 519/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0607\n",
      "Epoch 520/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0591\n",
      "Epoch 521/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0607\n",
      "Epoch 522/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0613\n",
      "Epoch 523/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0597 - val_loss: 0.0604\n",
      "Epoch 524/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0685\n",
      "Epoch 525/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 526/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0607\n",
      "Epoch 527/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0598\n",
      "Epoch 528/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0605\n",
      "Epoch 529/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0602\n",
      "Epoch 530/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0607\n",
      "Epoch 531/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0605\n",
      "Epoch 532/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0614\n",
      "Epoch 533/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0601\n",
      "Epoch 534/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 535/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0617\n",
      "Epoch 536/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0593 - val_loss: 0.0625\n",
      "Epoch 537/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0595\n",
      "Epoch 538/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0611\n",
      "Epoch 539/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0593 - val_loss: 0.0588\n",
      "Epoch 540/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0605\n",
      "Epoch 541/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0609\n",
      "Epoch 542/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0610\n",
      "Epoch 543/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0601\n",
      "Epoch 544/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0593 - val_loss: 0.0605\n",
      "Epoch 545/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0592\n",
      "Epoch 546/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0603\n",
      "Epoch 547/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0603\n",
      "Epoch 548/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0615\n",
      "Epoch 549/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0595\n",
      "Epoch 550/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0614\n",
      "Epoch 551/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0593\n",
      "Epoch 552/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0588 - val_loss: 0.0590\n",
      "Epoch 553/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0593 - val_loss: 0.0615\n",
      "Epoch 554/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0605\n",
      "Epoch 555/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0634\n",
      "Epoch 556/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0580\n",
      "Epoch 557/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0597\n",
      "Epoch 558/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0593 - val_loss: 0.0576\n",
      "Epoch 559/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0590 - val_loss: 0.0612\n",
      "Epoch 560/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0617\n",
      "Epoch 561/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0598\n",
      "Epoch 562/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0596\n",
      "Epoch 563/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0611\n",
      "Epoch 564/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0612\n",
      "Epoch 565/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0615\n",
      "Epoch 566/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0604\n",
      "Epoch 567/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0605\n",
      "Epoch 568/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0587 - val_loss: 0.0602\n",
      "Epoch 569/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 570/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0587\n",
      "Epoch 571/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0629\n",
      "Epoch 572/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0608\n",
      "Epoch 573/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0595\n",
      "Epoch 574/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0627\n",
      "Epoch 575/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0605\n",
      "Epoch 576/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0596\n",
      "Epoch 577/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0627\n",
      "Epoch 578/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0585\n",
      "Epoch 579/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0587 - val_loss: 0.0611\n",
      "Epoch 580/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0587 - val_loss: 0.0607\n",
      "Epoch 581/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0583\n",
      "Epoch 582/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0590\n",
      "Epoch 583/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0587\n",
      "Epoch 584/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0592 - val_loss: 0.0599\n",
      "Epoch 585/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0591\n",
      "Epoch 586/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0594\n",
      "Epoch 587/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0592\n",
      "Epoch 588/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0602\n",
      "Epoch 589/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0589 - val_loss: 0.0601\n",
      "Epoch 590/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0587 - val_loss: 0.0601\n",
      "Epoch 591/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0591 - val_loss: 0.0586\n",
      "Epoch 592/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0603\n",
      "Epoch 593/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0587 - val_loss: 0.0588\n",
      "Epoch 594/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0624\n",
      "Epoch 595/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0588 - val_loss: 0.0589\n",
      "Epoch 596/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0589 - val_loss: 0.0574\n",
      "Epoch 597/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0588 - val_loss: 0.0627\n",
      "Epoch 598/600\n",
      "3035/3035 [==============================] - 7s 2ms/step - loss: 0.0588 - val_loss: 0.0641\n",
      "Epoch 599/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0587 - val_loss: 0.0598\n",
      "Epoch 600/600\n",
      "3035/3035 [==============================] - 6s 2ms/step - loss: 0.0590 - val_loss: 0.0625\n",
      "1124/1124 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dict_train_history = {}\n",
    "dict_val_history = {}\n",
    "\n",
    "# train Neural Networks\n",
    "for w in dic_train_prep.keys():\n",
    "    \n",
    "    print(\"\\nTraining window: \", w)\n",
    "    \n",
    "    model = NN_model()\n",
    "    \n",
    "    history = model.fit(dic_train_prep[w][0],\n",
    "                        dic_train_prep[w][1],\n",
    "                        epochs = 600,\n",
    "                        batch_size=32,\n",
    "                        validation_data = (dic_val_prep[w][0], dic_val_prep[w][1])\n",
    "                       )\n",
    "    \n",
    "    dic_pred_prep[w][1] = model.predict(dic_pred_prep[w][0])\n",
    "    \n",
    "    dict_train_history[w] = [history.epoch, history.history[\"loss\"]]\n",
    "    dict_val_history[w] = [history.epoch, history.history[\"val_loss\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ea164",
   "metadata": {},
   "source": [
    "## Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b7ba792",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss curves\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 9))\n",
    "\n",
    "axs[0, 0].plot(dict_train_history[0][0], dict_train_history[0][1], 'b')\n",
    "axs[0, 0].plot(dict_val_history[0][0], dict_val_history[0][1], 'g')\n",
    "axs[0, 0].set_title('Window 0: prediction 2019')\n",
    "axs[0, 0].legend(['train','val'], loc='upper right')\n",
    "\n",
    "axs[0, 1].plot(dict_train_history[1][0], dict_train_history[1][1], 'b')\n",
    "axs[0, 1].plot(dict_val_history[1][0], dict_val_history[1][1], 'g')\n",
    "axs[0, 1].set_title('Window 1: prediction 2020')\n",
    "axs[0, 1].legend(['train','val'], loc='upper right')\n",
    "\n",
    "axs[1, 0].plot(dict_train_history[2][0], dict_train_history[2][1], 'b')\n",
    "axs[1, 0].plot(dict_val_history[2][0], dict_val_history[2][1], 'g')\n",
    "axs[1, 0].set_title('Window 2: prediction 2021')\n",
    "axs[1, 0].legend(['train','val'], loc='upper right')\n",
    "\n",
    "axs[1, 1].plot(dict_train_history[3][0], dict_train_history[3][1], 'b')\n",
    "axs[1, 1].plot(dict_val_history[3][0], dict_val_history[3][1], 'g')\n",
    "axs[1, 1].set_title('Window 3: prediction 2022')\n",
    "axs[1, 1].legend(['train','val'], loc='upper right')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='# epochs', ylabel='Loss')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf03c02",
   "metadata": {},
   "source": [
    "## Build dataframe with predicted weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c98e0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monta o dataframe com as predições de pesos em cada janela\n",
    "pred_list_df = []\n",
    "\n",
    "for w in dic_pred_prep.keys():\n",
    "    \n",
    "    # build dataframe with weights\n",
    "    predict_df = pd.DataFrame(dic_pred_prep[w][1], columns=['w_F1', 'w_F2', 'w_F3', 'w_F4'])\n",
    "    \n",
    "    # build dataframe with portfolios\n",
    "    port_df = pd.DataFrame(pred_port_list, columns=['F1', 'F2', 'F3', 'F4'])\n",
    "    \n",
    "    # concatenate dataframes\n",
    "    pred_port_df = pd.concat([port_df, predict_df], axis=1, ignore_index=False)\n",
    "    \n",
    "    # add window column\n",
    "    pred_port_df['window'] = w\n",
    "    \n",
    "    pred_list_df.append(pred_port_df)\n",
    "\n",
    "prediction_df = pd.concat(pred_list_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29784700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>w_F1</th>\n",
       "      <th>w_F2</th>\n",
       "      <th>w_F3</th>\n",
       "      <th>w_F4</th>\n",
       "      <th>window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alaska Black FIC FIA BDR Nível I</td>\n",
       "      <td>Apex Ações 30 FIC FIA</td>\n",
       "      <td>ARX Income FIC FIA</td>\n",
       "      <td>Atlas One FIC FIA</td>\n",
       "      <td>9.991860e-01</td>\n",
       "      <td>3.609063e-04</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska Black FIC FIA BDR Nível I</td>\n",
       "      <td>Apex Ações 30 FIC FIA</td>\n",
       "      <td>ARX Income FIC FIA</td>\n",
       "      <td>Atmos Ações FIC FIA</td>\n",
       "      <td>9.992449e-01</td>\n",
       "      <td>4.459676e-04</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska Black FIC FIA BDR Nível I</td>\n",
       "      <td>Apex Ações 30 FIC FIA</td>\n",
       "      <td>ARX Income FIC FIA</td>\n",
       "      <td>AZ Quest Small Mid Caps FIC FIA</td>\n",
       "      <td>3.882942e-01</td>\n",
       "      <td>3.490503e-05</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.611594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alaska Black FIC FIA BDR Nível I</td>\n",
       "      <td>Apex Ações 30 FIC FIA</td>\n",
       "      <td>ARX Income FIC FIA</td>\n",
       "      <td>Bahia AM Smid Caps Valor FIC FIA</td>\n",
       "      <td>9.999017e-01</td>\n",
       "      <td>5.857128e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alaska Black FIC FIA BDR Nível I</td>\n",
       "      <td>Apex Ações 30 FIC FIA</td>\n",
       "      <td>ARX Income FIC FIA</td>\n",
       "      <td>BNP Paribas Small Caps FIA</td>\n",
       "      <td>9.992549e-01</td>\n",
       "      <td>4.693182e-04</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143835</th>\n",
       "      <td>Squadra Long Only FIC FIA</td>\n",
       "      <td>Tempo Capital Manacá FIC FIA</td>\n",
       "      <td>Velt FIC FIA</td>\n",
       "      <td>VOKIN GBV</td>\n",
       "      <td>7.703106e-07</td>\n",
       "      <td>6.049842e-09</td>\n",
       "      <td>0.810736</td>\n",
       "      <td>0.189263</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143836</th>\n",
       "      <td>Squadra Long Only FIC FIA</td>\n",
       "      <td>Tempo Capital Manacá FIC FIA</td>\n",
       "      <td>Velt FIC FIA</td>\n",
       "      <td>XP Investor FIA</td>\n",
       "      <td>6.892502e-11</td>\n",
       "      <td>3.121165e-13</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143837</th>\n",
       "      <td>Squadra Long Only FIC FIA</td>\n",
       "      <td>Tempo Capital Manacá FIC FIA</td>\n",
       "      <td>VOKIN GBV</td>\n",
       "      <td>XP Investor FIA</td>\n",
       "      <td>3.212989e-05</td>\n",
       "      <td>2.318169e-06</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143838</th>\n",
       "      <td>Squadra Long Only FIC FIA</td>\n",
       "      <td>Velt FIC FIA</td>\n",
       "      <td>VOKIN GBV</td>\n",
       "      <td>XP Investor FIA</td>\n",
       "      <td>5.235630e-08</td>\n",
       "      <td>9.869703e-10</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>0.006071</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143839</th>\n",
       "      <td>Tempo Capital Manacá FIC FIA</td>\n",
       "      <td>Velt FIC FIA</td>\n",
       "      <td>VOKIN GBV</td>\n",
       "      <td>XP Investor FIA</td>\n",
       "      <td>1.583030e-06</td>\n",
       "      <td>6.704121e-07</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.999918</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143840 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      F1                            F2  \\\n",
       "0       Alaska Black FIC FIA BDR Nível I         Apex Ações 30 FIC FIA   \n",
       "1       Alaska Black FIC FIA BDR Nível I         Apex Ações 30 FIC FIA   \n",
       "2       Alaska Black FIC FIA BDR Nível I         Apex Ações 30 FIC FIA   \n",
       "3       Alaska Black FIC FIA BDR Nível I         Apex Ações 30 FIC FIA   \n",
       "4       Alaska Black FIC FIA BDR Nível I         Apex Ações 30 FIC FIA   \n",
       "...                                  ...                           ...   \n",
       "143835         Squadra Long Only FIC FIA  Tempo Capital Manacá FIC FIA   \n",
       "143836         Squadra Long Only FIC FIA  Tempo Capital Manacá FIC FIA   \n",
       "143837         Squadra Long Only FIC FIA  Tempo Capital Manacá FIC FIA   \n",
       "143838         Squadra Long Only FIC FIA                  Velt FIC FIA   \n",
       "143839      Tempo Capital Manacá FIC FIA                  Velt FIC FIA   \n",
       "\n",
       "                        F3                                F4          w_F1  \\\n",
       "0       ARX Income FIC FIA                 Atlas One FIC FIA  9.991860e-01   \n",
       "1       ARX Income FIC FIA               Atmos Ações FIC FIA  9.992449e-01   \n",
       "2       ARX Income FIC FIA   AZ Quest Small Mid Caps FIC FIA  3.882942e-01   \n",
       "3       ARX Income FIC FIA  Bahia AM Smid Caps Valor FIC FIA  9.999017e-01   \n",
       "4       ARX Income FIC FIA        BNP Paribas Small Caps FIA  9.992549e-01   \n",
       "...                    ...                               ...           ...   \n",
       "143835        Velt FIC FIA                         VOKIN GBV  7.703106e-07   \n",
       "143836        Velt FIC FIA                   XP Investor FIA  6.892502e-11   \n",
       "143837           VOKIN GBV                   XP Investor FIA  3.212989e-05   \n",
       "143838           VOKIN GBV                   XP Investor FIA  5.235630e-08   \n",
       "143839           VOKIN GBV                   XP Investor FIA  1.583030e-06   \n",
       "\n",
       "                w_F2      w_F3      w_F4  window  \n",
       "0       3.609063e-04  0.000033  0.000420       0  \n",
       "1       4.459676e-04  0.000030  0.000279       0  \n",
       "2       3.490503e-05  0.000077  0.611594       0  \n",
       "3       5.857128e-05  0.000003  0.000037       0  \n",
       "4       4.693182e-04  0.000102  0.000174       0  \n",
       "...              ...       ...       ...     ...  \n",
       "143835  6.049842e-09  0.810736  0.189263       3  \n",
       "143836  3.121165e-13  0.999993  0.000007       3  \n",
       "143837  2.318169e-06  0.000160  0.999806       3  \n",
       "143838  9.869703e-10  0.993929  0.006071       3  \n",
       "143839  6.704121e-07  0.000080  0.999918       3  \n",
       "\n",
       "[143840 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab9ff3",
   "metadata": {},
   "source": [
    "## Download predicted weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a4e8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(r'./predicted_weights/FIA1_3x20layers_relu_20142022_pred_weights_output.csv',\n",
    "                    encoding = 'utf-8-sig',\n",
    "                    index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26644592",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
